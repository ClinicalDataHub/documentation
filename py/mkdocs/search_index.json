{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to the healthcare.ai documentation!\n\n\nThe purpose of this python package is to streamline healthcare machine\nlearning. It does this by including functionality specific to\nhealthcare, as well as simplifying the workflow of creating and\ndeploying models.\n\n\nThe aim of \nhealthcareai\n is to streamline machine learning in healthcare. The package has two main goals:\n\n\n\n\nAllow one to easily create models based on tabular data, and deploy a best model that pushes predictions to SQL Server.\n\n\nProvide tools related to data cleaning, manipulation, and imputation.\n\n\n\n\nDo I want this package or the \nR package\n?\n\n\nChoose this Python package if one of the following apply:\n\n\n\n\nYou're familiar with python\n\n\nYou're familiar with machine learning\n\n\nYou're working with 5M+ rows (which is rare)\n\n\n\n\nOtherwise, the \nR package\n is recommended, as it\ncurrently has more features and R is more newbie-friendly", 
            "title": "Introduction"
        }, 
        {
            "location": "/#welcome-to-the-healthcareai-documentation", 
            "text": "The purpose of this python package is to streamline healthcare machine\nlearning. It does this by including functionality specific to\nhealthcare, as well as simplifying the workflow of creating and\ndeploying models.  The aim of  healthcareai  is to streamline machine learning in healthcare. The package has two main goals:   Allow one to easily create models based on tabular data, and deploy a best model that pushes predictions to SQL Server.  Provide tools related to data cleaning, manipulation, and imputation.", 
            "title": "Welcome to the healthcare.ai documentation!"
        }, 
        {
            "location": "/#do-i-want-this-package-or-the-r-package", 
            "text": "Choose this Python package if one of the following apply:   You're familiar with python  You're familiar with machine learning  You're working with 5M+ rows (which is rare)   Otherwise, the  R package  is recommended, as it\ncurrently has more features and R is more newbie-friendly", 
            "title": "Do I want this package or the R package?"
        }, 
        {
            "location": "/getting_started/", 
            "text": "Getting started with healthcare.ai\n\n\nWhat can you do with this package?\n\n\n\n\nFill in missing data via imputation\n\n\nCreate and compare models based on your data\n\n\nSave a model to produce daily predictions\n\n\nWrite predictions back to a database\n\n\nLearn what factor drives each prediction\n\n\n\n\nInstallation\n\n\nWindows\n\n\n\n\nIf you haven't, install 64-bit Python 3.5 via \nthe Anaconda distribution\n\n\nOpen the terminal (i.e., CMD or PowerShell, if using Windows)\n\n\nRun \nconda install pyodbc\n\n\nUpgrade to latest scipy (note that upgrade command took forever)\n\n\nRun \nconda remove scipy\n\n\nRun \nconda install scipy\n\n\nTo install the latest release, run \n\n\npip install healthcareai\n\n\n\n\n\n\nIf you know what you're doing, and instead want the bleeding-edge version direct from our github repo, run\n\n\npip install https://github.com/HealthCatalystSLC/healthcareai-py/zipball/master\n\n\n\n\n\n\n\n\nLinux\n\n\nYou may need to install the following dependencies:\n- \nsudo apt-get install python-tk\n\n- \nsudo pip install pyodbc\n\n    - Note you'll might run into trouble with the \npyodbc\n dependency. You may first need to run \nsudo apt-get install unixodbc-dev\n then retry \nsudo pip install pyodbc\n. Credit \nstackoverflow\n\n\nOnce you have the dependencies satisfied run \npip install healthcareai\n or \nsudo pip install healthcareai\n\n\nmacOS\n\n\n\n\npip install healthcareai\n or \nsudo pip install healthcareai\n\n\n\n\nLinux and macOS (via docker)\n\n\n\n\nInstall \ndocker\n\n\nClone this repo (look for the green button on the repo main page)\n\n\ncd into the cloned directory\n\n\nrun \ndocker build -t healthcareai .\n\n\nrun the docker instance with \ndocker run -p 8888:8888 healthcareai\n \n\n\nYou should then have a jupyter notebook available on \nhttp://localhost:8888\n.\n\n\n\n\nVerify Installation\n\n\nTo verify that \nhealthcareai\n installed correctly, open a terminal and run \npython\n. This opens an interactive python console (also known as a \nREPL\n). Then enter this command: \nfrom healthcareai import develop_supervised_model\n and hit enter. If no error is thrown, you are ready to rock.\n\n\nIf you did get an error, or run into other installation issues, please \nlet us know\n or better yet post on \nStack Overflow\n(with the healthcare-ai tag) so we can help others along this process.\n\n\nGetting started\n\n\n\n\nVisit \nhealthcare.ai\n to read the docs and find examples.\n\n\nIncluding this \nnotebook\n\n\n\n\n\n\nOpen Sphinx (which installed with Anaconda) and copy the examples into a new file\n\n\nModify the queries and parameters to match your data\n\n\nIf you plan on deploying a model (ie, pushing predictions to SQL Server), run this in SSMS beforehand:\n\n\n\n\nCREATE TABLE [SAM].[dbo].[HCPyDeployClassificationBASE] (\n [BindingID] [int] ,\n [BindingNM] [varchar] (255),\n [LastLoadDTS] [datetime2] (7),\n [PatientEncounterID] [decimal] (38, 0), --\n change to your grain col\n [PredictedProbNBR] [decimal] (38, 2),\n [Factor1TXT] [varchar] (255),\n [Factor2TXT] [varchar] (255),\n [Factor3TXT] [varchar] (255))\n\nCREATE TABLE [SAM].[dbo].[HCPyDeployRegressionBASE] (\n [BindingID] [int],\n [BindingNM] [varchar] (255),\n [LastLoadDTS] [datetime2] (7),\n [PatientEncounterID] [decimal] (38, 0), --\n change to your grain col\n [PredictedValueNBR] [decimal] (38, 2),\n [Factor1TXT] [varchar] (255),\n [Factor2TXT] [varchar] (255),\n [Factor3TXT] [varchar] (255))\n\n\n\n\nNote that we're currently working on easy connections to other types of databases.\n\n\nFor Issues\n\n\n\n\nDouble check that the code follows the examples at \nhealthcare.ai/py\n\n\nIf you're still seeing an error, \ncreate a post in our Google Group\n that contains\n\n\nDetails on your environment (OS, database type, R vs Py)\n\n\nGoals (ie, what are you trying to accomplish)\n\n\nCrystal clear steps for reproducing the error", 
            "title": "Getting started"
        }, 
        {
            "location": "/getting_started/#getting-started-with-healthcareai", 
            "text": "", 
            "title": "Getting started with healthcare.ai"
        }, 
        {
            "location": "/getting_started/#what-can-you-do-with-this-package", 
            "text": "Fill in missing data via imputation  Create and compare models based on your data  Save a model to produce daily predictions  Write predictions back to a database  Learn what factor drives each prediction", 
            "title": "What can you do with this package?"
        }, 
        {
            "location": "/getting_started/#installation", 
            "text": "", 
            "title": "Installation"
        }, 
        {
            "location": "/getting_started/#windows", 
            "text": "If you haven't, install 64-bit Python 3.5 via  the Anaconda distribution  Open the terminal (i.e., CMD or PowerShell, if using Windows)  Run  conda install pyodbc  Upgrade to latest scipy (note that upgrade command took forever)  Run  conda remove scipy  Run  conda install scipy  To install the latest release, run   pip install healthcareai    If you know what you're doing, and instead want the bleeding-edge version direct from our github repo, run  pip install https://github.com/HealthCatalystSLC/healthcareai-py/zipball/master", 
            "title": "Windows"
        }, 
        {
            "location": "/getting_started/#linux", 
            "text": "You may need to install the following dependencies:\n-  sudo apt-get install python-tk \n-  sudo pip install pyodbc \n    - Note you'll might run into trouble with the  pyodbc  dependency. You may first need to run  sudo apt-get install unixodbc-dev  then retry  sudo pip install pyodbc . Credit  stackoverflow  Once you have the dependencies satisfied run  pip install healthcareai  or  sudo pip install healthcareai", 
            "title": "Linux"
        }, 
        {
            "location": "/getting_started/#macos", 
            "text": "pip install healthcareai  or  sudo pip install healthcareai", 
            "title": "macOS"
        }, 
        {
            "location": "/getting_started/#linux-and-macos-via-docker", 
            "text": "Install  docker  Clone this repo (look for the green button on the repo main page)  cd into the cloned directory  run  docker build -t healthcareai .  run the docker instance with  docker run -p 8888:8888 healthcareai    You should then have a jupyter notebook available on  http://localhost:8888 .", 
            "title": "Linux and macOS (via docker)"
        }, 
        {
            "location": "/getting_started/#verify-installation", 
            "text": "To verify that  healthcareai  installed correctly, open a terminal and run  python . This opens an interactive python console (also known as a  REPL ). Then enter this command:  from healthcareai import develop_supervised_model  and hit enter. If no error is thrown, you are ready to rock.  If you did get an error, or run into other installation issues, please  let us know  or better yet post on  Stack Overflow (with the healthcare-ai tag) so we can help others along this process.", 
            "title": "Verify Installation"
        }, 
        {
            "location": "/getting_started/#getting-started", 
            "text": "Visit  healthcare.ai  to read the docs and find examples.  Including this  notebook    Open Sphinx (which installed with Anaconda) and copy the examples into a new file  Modify the queries and parameters to match your data  If you plan on deploying a model (ie, pushing predictions to SQL Server), run this in SSMS beforehand:   CREATE TABLE [SAM].[dbo].[HCPyDeployClassificationBASE] (\n [BindingID] [int] ,\n [BindingNM] [varchar] (255),\n [LastLoadDTS] [datetime2] (7),\n [PatientEncounterID] [decimal] (38, 0), --  change to your grain col\n [PredictedProbNBR] [decimal] (38, 2),\n [Factor1TXT] [varchar] (255),\n [Factor2TXT] [varchar] (255),\n [Factor3TXT] [varchar] (255))\n\nCREATE TABLE [SAM].[dbo].[HCPyDeployRegressionBASE] (\n [BindingID] [int],\n [BindingNM] [varchar] (255),\n [LastLoadDTS] [datetime2] (7),\n [PatientEncounterID] [decimal] (38, 0), --  change to your grain col\n [PredictedValueNBR] [decimal] (38, 2),\n [Factor1TXT] [varchar] (255),\n [Factor2TXT] [varchar] (255),\n [Factor3TXT] [varchar] (255))  Note that we're currently working on easy connections to other types of databases.", 
            "title": "Getting started"
        }, 
        {
            "location": "/getting_started/#for-issues", 
            "text": "Double check that the code follows the examples at  healthcare.ai/py  If you're still seeing an error,  create a post in our Google Group  that contains  Details on your environment (OS, database type, R vs Py)  Goals (ie, what are you trying to accomplish)  Crystal clear steps for reproducing the error", 
            "title": "For Issues"
        }, 
        {
            "location": "/FAQ/", 
            "text": "Frequently asked questions\n\n\nWho is this project for?\n\n\nWhile data scientists in healthcare will likely find this project\nvaluable, the target audience for healthcare.ai are those BI developers,\ndata architects, and SQL developers that would love to create\nappropriate and accurate models with healthcare data. While existing\nmachine learning packages are certainly irreplaceable, we think that\nthere is a set of data problems specific to healthcare that warrant new\ntools.\n\n\nHow does healthcare.ai focus on healthcare?\n\n\nhealthcare.ai differs from other machine learning packages in that it\nfocuses on data issues specific to healthcare. This means that we pay\nattention to longitudinal questions, offer an easy way to do\nrisk-adjusted comparisons, and provide easy connections and deployment\nto databases.\n\n\nWho started this project?\n\n\nThis project began in the data science group at Health Catalyst, a Salt\nLake City-based company based focused on improving healthcare outcomes.\n\n\nWhy was it open-sourced?\n\n\nWe believe that everyone benefits when healthcare is made more efficient\nand outcomes are improved. Machine learning is surprisingly still fairly\nnew to healthcare and we want to quickly take healthcare down the\nmachine learning adoption path. We believe that making helpful, simple\ntools widely available is one small way to help healthcare organizations\ntransform their data into actionable insight that can be used to improve\noutcomes.\n\n\nHow can I contact the authors\n\n\nWe'd love to hear from you! We welcome complaints, suggestions, and\ncontributions.\n\n\nhealthcare.ai/contact.html\n\n\nTwitter: \n@levithatcher\n Email:", 
            "title": "FAQ"
        }, 
        {
            "location": "/FAQ/#frequently-asked-questions", 
            "text": "", 
            "title": "Frequently asked questions"
        }, 
        {
            "location": "/FAQ/#who-is-this-project-for", 
            "text": "While data scientists in healthcare will likely find this project\nvaluable, the target audience for healthcare.ai are those BI developers,\ndata architects, and SQL developers that would love to create\nappropriate and accurate models with healthcare data. While existing\nmachine learning packages are certainly irreplaceable, we think that\nthere is a set of data problems specific to healthcare that warrant new\ntools.", 
            "title": "Who is this project for?"
        }, 
        {
            "location": "/FAQ/#how-does-healthcareai-focus-on-healthcare", 
            "text": "healthcare.ai differs from other machine learning packages in that it\nfocuses on data issues specific to healthcare. This means that we pay\nattention to longitudinal questions, offer an easy way to do\nrisk-adjusted comparisons, and provide easy connections and deployment\nto databases.", 
            "title": "How does healthcare.ai focus on healthcare?"
        }, 
        {
            "location": "/FAQ/#who-started-this-project", 
            "text": "This project began in the data science group at Health Catalyst, a Salt\nLake City-based company based focused on improving healthcare outcomes.", 
            "title": "Who started this project?"
        }, 
        {
            "location": "/FAQ/#why-was-it-open-sourced", 
            "text": "We believe that everyone benefits when healthcare is made more efficient\nand outcomes are improved. Machine learning is surprisingly still fairly\nnew to healthcare and we want to quickly take healthcare down the\nmachine learning adoption path. We believe that making helpful, simple\ntools widely available is one small way to help healthcare organizations\ntransform their data into actionable insight that can be used to improve\noutcomes.", 
            "title": "Why was it open-sourced?"
        }, 
        {
            "location": "/FAQ/#how-can-i-contact-the-authors", 
            "text": "We'd love to hear from you! We welcome complaints, suggestions, and\ncontributions.  healthcare.ai/contact.html  Twitter:  @levithatcher  Email:", 
            "title": "How can I contact the authors"
        }, 
        {
            "location": "/hints/", 
            "text": "Hints and tips\n\n\nGathering the data\n\n\nIf you have interesting data in a CSV file or even a cross serveral\ndatabases on a single server, you are in good shape. While it's easiest\nto pull data into the package via a single table, one can also use joins\nto gather data from separate tables or databases. What's most important\nis the following:\n\n\n\n\nYou have a column you're excited about predicting and some data that\n    might be relevant\n\n\nIf you're predicting a binary outcome (ie, 0 or 1), you have to\n    \nconvert the column to be Y or\n    N\n.\n\n\n\n\nPre-processing\n\n\nIt's almost always helpful to do some \nfeature\nengineering\n before\ncreating a model. Here are some practical examples of that:\n\n\n\n\nIf you think the thing your predicting might have a seasonal\n    pattern, you could\n    \nconvert\n a date-time\n    column into columns representing DayOfWeek, DayOfMonth, WeekOfYear,\n    etc.\n\n\nIf you have rows with both a latitude and longitude, it may be\n    beneficial to \nadd a zip code column\n\n    (for example)\n\n\n\n\nModel building tips\n\n\n\n\nStart small. You can often get a good idea of model performance by\n    starting with 10k rows instead of 1M.\n\n\nDon't throw out rows with missing values. We'll help you experiment\n    with\n    \nimputation\n,\n    which may improve the model's performance.\n\n\nFocus on new features. Rather than finding more rows of the same\n    columns, finding better columns (ie, features) will give better\n    results.", 
            "title": "Hints and tips"
        }, 
        {
            "location": "/hints/#hints-and-tips", 
            "text": "", 
            "title": "Hints and tips"
        }, 
        {
            "location": "/hints/#gathering-the-data", 
            "text": "If you have interesting data in a CSV file or even a cross serveral\ndatabases on a single server, you are in good shape. While it's easiest\nto pull data into the package via a single table, one can also use joins\nto gather data from separate tables or databases. What's most important\nis the following:   You have a column you're excited about predicting and some data that\n    might be relevant  If you're predicting a binary outcome (ie, 0 or 1), you have to\n     convert the column to be Y or\n    N .", 
            "title": "Gathering the data"
        }, 
        {
            "location": "/hints/#pre-processing", 
            "text": "It's almost always helpful to do some  feature\nengineering  before\ncreating a model. Here are some practical examples of that:   If you think the thing your predicting might have a seasonal\n    pattern, you could\n     convert  a date-time\n    column into columns representing DayOfWeek, DayOfMonth, WeekOfYear,\n    etc.  If you have rows with both a latitude and longitude, it may be\n    beneficial to  add a zip code column \n    (for example)", 
            "title": "Pre-processing"
        }, 
        {
            "location": "/hints/#model-building-tips", 
            "text": "Start small. You can often get a good idea of model performance by\n    starting with 10k rows instead of 1M.  Don't throw out rows with missing values. We'll help you experiment\n    with\n     imputation ,\n    which may improve the model's performance.  Focus on new features. Rather than finding more rows of the same\n    columns, finding better columns (ie, features) will give better\n    results.", 
            "title": "Model building tips"
        }, 
        {
            "location": "/develop/", 
            "text": "Developing and comparing models\n\n\nWhat is \nDevelopSupervisedModel\n?\n\n\n\n\nThis class let's one create and compare custom models on diverse\n    datasets.\n\n\nOne can do both classification (ie, predict Y/N) as well as\n    regression (ie, predict a numeric field).\n\n\nTo jump straight to an example notebook, see\n    \nhere\n\n\n\n\nAm I ready for model creation?\n\n\nMaybe. It'll help if you follow these guidelines:\n\n\n\n\n\n\nDon't use 0 or 1 for the independent variable when doing\n    classification. Use Y/N instead. The IIF function in T-SQL may\n    help here.\n\n\nDon't pull in test data in this step. In other words, we just pull\n    in those rows where the target (ie, predicted column has a value\n    already).\n\n\n\n\n\n\nOf course, feature engineering is always a good idea.\n\n\nStep 1: Pull in the data\n\n\nFor SQL:\n\n\nimport pyodbc\ncnxn = pyodbc.connect(\nSERVER=localhost;\n                        DRIVER={SQL Server Native Client 11.0};\n                        Trusted_Connection=yes;\n                        autocommit=True\n)\n\n df = pd.read_sql(\n     sql=\nSELECT *\n            FROM [SAM].[dbo].[HCPyDiabetesClinical]\n,\n     con=cnxn)\n\n\n # Handle missing data (if needed)\n df.replace(['None'],[None],inplace=True)\n\n\n\n\nFor CSV:\n\n\ndf = pd.read_csv('healthcareai/tests/fixtures/HCPyDiabetesClinical.csv',\n                 na_values=['None'])\n\n\n\n\nStep 2: Set your data-prep parameters\n\n\nThe \nDevelopSupervisedModel\n class cleans and prepares the data before\nmodel creation\n\n\n\n\nReturn\n: an object.\n\n\nArguments\n:\n    :   -   \nmodeltype\n: a string. This will either be\n            'classification' or 'regression'.\n        -   \ndf\n: a data frame. The data your model will be based on.\n        -   \npredictedcol\n: a string. Name of variable (or column)\n            that you want to predict.\n        -   \ngraincol\n: a string, defaults to None. Name of possible\n            GrainID column in your dataset. If specified, this column\n            will be removed, as it won't help the algorithm.\n        -   \nimpute\n: a boolean. Whether to impute by replacing NULLs\n            with column mean (for numeric columns) or column mode (for\n            categorical columns).\n        -   \ndebug\n: a boolean, defaults to False. If TRUE, console\n            output when comparing models is verbose for easier\n            debugging.\n\n\n\n\nExample code:\n\n\no = DevelopSupervisedModel(modeltype='classification',\n                           df=df,\n                           predictedcol='ThirtyDayReadmitFLG',\n                           graincol='PatientEncounterID', #OPTIONAL\n                           impute=True,\n                           debug=False)\n\n\n\n\nStep 3: Create and compare models\n\n\nExample code:\n\n\n# Run the linear model\no.linear(cores=1)\n\n# Run the random forest model\no.random_forest(cores=1)\n\n\n\n\nGo further using utility methods\n\n\nThe \nplot_rffeature_importance\n method plots the input columns in order\nof importance to the model.\n\n\n\n\nReturn\n: a plot.\n\n\nArguments\n:\n    :   -   \nsave\n: a boolean, defaults to False. If True, the plot is\n            saved to the location displayed in the console.\n\n\n\n\nExample code:\n\n\n# Look at the feature importance rankings\no.plot_rffeature_importance(save=False)\n\n\n\n\nThe \nplot_roc\n method plots the AU_ROC chart, for easier model\ncomparison.\n\n\n\n\nReturn\n: a plot.\n\n\nArguments\n:\n    :   -   \nsave\n: a boolean, defaults to False. If True, the plot is\n            saved to the location displayed in the console.\n        -   \ndebug\n: a boolean. If True, console output is verbose for\n            easier debugging.\n\n\n\n\nExample code:\n\n\n# Create ROC plot to compare the two models\no.plot_roc(debug=False,\n           save=False)\n\n\n\n\nFull example code\n\n\nNote: you can run (out-of-the-box) from the healthcareai-py folder:\n\n\nfrom healthcareai import DevelopSupervisedModel\nimport pandas as pd\nimport time\n\ndef main():\n\n    t0 = time.time()\n\n    # CSV snippet for reading data into dataframe\n    df = pd.read_csv('healthcareai/tests/fixtures/HCPyDiabetesClinical.csv',\n                    na_values=['None'])\n\n    # SQL snippet for reading data into dataframe\n    import pyodbc\n    cnxn = pyodbc.connect(\nSERVER=localhost;\n                            DRIVER={SQL Server Native Client 11.0};\n                            Trusted_Connection=yes;\n                            autocommit=True\n)\n\n    df = pd.read_sql(\n        sql=\nSELECT *\n            FROM [SAM].[dbo].[HCPyDiabetesClinical]\n            -- In this step, just grab rows that have a target\n            WHERE ThirtyDayReadmitFLG is not null\n,\n        con=cnxn)\n\n    # Set None string to be None type\n    df.replace(['None'],[None],inplace=True)\n\n    # Look at data that's been pulled in\n    print(df.head())\n    print(df.dtypes)\n\n    # Drop columns that won't help machine learning\n    df.drop(['PatientID','InTestWindowFLG'],axis=1,inplace=True)\n\n    # Step 1: compare two models\n    o = DevelopSupervisedModel(modeltype='classification',\n                            df=df,\n                            predictedcol='ThirtyDayReadmitFLG',\n                            graincol='PatientEncounterID', #OPTIONAL\n                            impute=True,\n                            debug=False)\n\n    # Run the linear model\n    o.linear(cores=1)\n\n    # Run the random forest model\n    o.random_forest(cores=1,\n                    tune=True)\n\n    # Look at the RF feature importance rankings\n    o.plot_rffeature_importance(save=False)\n\n    # Create ROC plot to compare the two models\n    o.plot_roc(debug=False,\n            save=False)\n\n    print('\\nTime:\\n', time.time() - t0)\n\nif __name__ == \n__main__\n:\n    main()", 
            "title": "Developing and comparing models.md"
        }, 
        {
            "location": "/develop/#developing-and-comparing-models", 
            "text": "", 
            "title": "Developing and comparing models"
        }, 
        {
            "location": "/develop/#what-is-developsupervisedmodel", 
            "text": "This class let's one create and compare custom models on diverse\n    datasets.  One can do both classification (ie, predict Y/N) as well as\n    regression (ie, predict a numeric field).  To jump straight to an example notebook, see\n     here", 
            "title": "What is DevelopSupervisedModel?"
        }, 
        {
            "location": "/develop/#am-i-ready-for-model-creation", 
            "text": "Maybe. It'll help if you follow these guidelines:    Don't use 0 or 1 for the independent variable when doing\n    classification. Use Y/N instead. The IIF function in T-SQL may\n    help here.  Don't pull in test data in this step. In other words, we just pull\n    in those rows where the target (ie, predicted column has a value\n    already).    Of course, feature engineering is always a good idea.", 
            "title": "Am I ready for model creation?"
        }, 
        {
            "location": "/develop/#step-1-pull-in-the-data", 
            "text": "For SQL:  import pyodbc\ncnxn = pyodbc.connect( SERVER=localhost;\n                        DRIVER={SQL Server Native Client 11.0};\n                        Trusted_Connection=yes;\n                        autocommit=True )\n\n df = pd.read_sql(\n     sql= SELECT *\n            FROM [SAM].[dbo].[HCPyDiabetesClinical] ,\n     con=cnxn)\n\n\n # Handle missing data (if needed)\n df.replace(['None'],[None],inplace=True)  For CSV:  df = pd.read_csv('healthcareai/tests/fixtures/HCPyDiabetesClinical.csv',\n                 na_values=['None'])", 
            "title": "Step 1: Pull in the data"
        }, 
        {
            "location": "/develop/#step-2-set-your-data-prep-parameters", 
            "text": "The  DevelopSupervisedModel  class cleans and prepares the data before\nmodel creation   Return : an object.  Arguments :\n    :   -    modeltype : a string. This will either be\n            'classification' or 'regression'.\n        -    df : a data frame. The data your model will be based on.\n        -    predictedcol : a string. Name of variable (or column)\n            that you want to predict.\n        -    graincol : a string, defaults to None. Name of possible\n            GrainID column in your dataset. If specified, this column\n            will be removed, as it won't help the algorithm.\n        -    impute : a boolean. Whether to impute by replacing NULLs\n            with column mean (for numeric columns) or column mode (for\n            categorical columns).\n        -    debug : a boolean, defaults to False. If TRUE, console\n            output when comparing models is verbose for easier\n            debugging.   Example code:  o = DevelopSupervisedModel(modeltype='classification',\n                           df=df,\n                           predictedcol='ThirtyDayReadmitFLG',\n                           graincol='PatientEncounterID', #OPTIONAL\n                           impute=True,\n                           debug=False)", 
            "title": "Step 2: Set your data-prep parameters"
        }, 
        {
            "location": "/develop/#step-3-create-and-compare-models", 
            "text": "Example code:  # Run the linear model\no.linear(cores=1)\n\n# Run the random forest model\no.random_forest(cores=1)", 
            "title": "Step 3: Create and compare models"
        }, 
        {
            "location": "/develop/#go-further-using-utility-methods", 
            "text": "The  plot_rffeature_importance  method plots the input columns in order\nof importance to the model.   Return : a plot.  Arguments :\n    :   -    save : a boolean, defaults to False. If True, the plot is\n            saved to the location displayed in the console.   Example code:  # Look at the feature importance rankings\no.plot_rffeature_importance(save=False)  The  plot_roc  method plots the AU_ROC chart, for easier model\ncomparison.   Return : a plot.  Arguments :\n    :   -    save : a boolean, defaults to False. If True, the plot is\n            saved to the location displayed in the console.\n        -    debug : a boolean. If True, console output is verbose for\n            easier debugging.   Example code:  # Create ROC plot to compare the two models\no.plot_roc(debug=False,\n           save=False)", 
            "title": "Go further using utility methods"
        }, 
        {
            "location": "/develop/#full-example-code", 
            "text": "Note: you can run (out-of-the-box) from the healthcareai-py folder:  from healthcareai import DevelopSupervisedModel\nimport pandas as pd\nimport time\n\ndef main():\n\n    t0 = time.time()\n\n    # CSV snippet for reading data into dataframe\n    df = pd.read_csv('healthcareai/tests/fixtures/HCPyDiabetesClinical.csv',\n                    na_values=['None'])\n\n    # SQL snippet for reading data into dataframe\n    import pyodbc\n    cnxn = pyodbc.connect( SERVER=localhost;\n                            DRIVER={SQL Server Native Client 11.0};\n                            Trusted_Connection=yes;\n                            autocommit=True )\n\n    df = pd.read_sql(\n        sql= SELECT *\n            FROM [SAM].[dbo].[HCPyDiabetesClinical]\n            -- In this step, just grab rows that have a target\n            WHERE ThirtyDayReadmitFLG is not null ,\n        con=cnxn)\n\n    # Set None string to be None type\n    df.replace(['None'],[None],inplace=True)\n\n    # Look at data that's been pulled in\n    print(df.head())\n    print(df.dtypes)\n\n    # Drop columns that won't help machine learning\n    df.drop(['PatientID','InTestWindowFLG'],axis=1,inplace=True)\n\n    # Step 1: compare two models\n    o = DevelopSupervisedModel(modeltype='classification',\n                            df=df,\n                            predictedcol='ThirtyDayReadmitFLG',\n                            graincol='PatientEncounterID', #OPTIONAL\n                            impute=True,\n                            debug=False)\n\n    # Run the linear model\n    o.linear(cores=1)\n\n    # Run the random forest model\n    o.random_forest(cores=1,\n                    tune=True)\n\n    # Look at the RF feature importance rankings\n    o.plot_rffeature_importance(save=False)\n\n    # Create ROC plot to compare the two models\n    o.plot_roc(debug=False,\n            save=False)\n\n    print('\\nTime:\\n', time.time() - t0)\n\nif __name__ ==  __main__ :\n    main()", 
            "title": "Full example code"
        }, 
        {
            "location": "/deploy/", 
            "text": "Deploying and saving a model\n\n\nWhat is \nDeploySupervisedModel\n?\n\n\n\n\nThis class lets one save a model (for recurrent use) and push\n    predictions to a database\n\n\nOne can do both classification (ie, predict Y/N) as well as\n    regression (ie, predict a numeric field).\n\n\n\n\nAm I ready for model deployment?\n\n\nOnly if you've already completed these steps:\n\n\n\n\nYou've found a model work that works well on your data\n\n\nYou've created a column called InTestWindowFLG (or something\n    similar), where 'Y' denotes rows that need a prediction and 'N' for\n    rows that train the model.\n\n\nYou've created the SQL table structure to receive predictions\n\n\n\n\nFor classification predictions:\n\n\nCREATE TABLE [SAM].[dbo].[HCPyDeployClassificationBASE] (\n  [BindingID] [int] , \n  [BindingNM] [varchar] (255), \n  [LastLoadDTS] [datetime2] (7), \n  [PatientEncounterID] [decimal] (38, 0), --\n change to your grain col\n  [PredictedProbNBR] [decimal] (38, 2),\n  [Factor1TXT] [varchar] (255), \n  [Factor2TXT] [varchar] (255), \n  [Factor3TXT] [varchar] (255))\n\n\n\n\nFor regression predictions:\n\n\nCREATE TABLE [SAM].[dbo].[HCPyDeployRegressionBASE] (\n  [BindingID] [int], \n  [BindingNM] [varchar] (255), \n  [LastLoadDTS] [datetime2] (7), \n  [PatientEncounterID] [decimal] (38, 0), --\n change to your grain col\n  [PredictedValueNBR] [decimal] (38, 2), \n  [Factor1TXT] [varchar] (255), \n  [Factor2TXT] [varchar] (255), \n  [Factor3TXT] [varchar] (255))\n\n\n\n\nStep 1: Pull in the data\n\n\nFor SQL:\n\n\nimport pyodbc\ncnxn = pyodbc.connect(\nSERVER=localhost;\n                        DRIVER={SQL Server Native Client 11.0};\n                        Trusted_Connection=yes;\n                        autocommit=True\n)\n\n df = pd.read_sql(\n     sql=\nSELECT\n            *\n            FROM [SAM].[dbo].[HCPyDiabetesClinical]\n,\n     con=cnxn)\n\n\n # Handle missing data (if needed)\n df.replace(['None'],[None],inplace=True)\n\n\n\n\nFor CSV:\n\n\ndf = pd.read_csv('healthcareai/tests/fixtures/HCPyDiabetesClinical.csv',\n                 na_values=['None'])\n\n\n\n\nStep 2: Set your data-prep parameters\n\n\nThe \nDeploySupervisedModel\n cleans and prepares the data prior to model\ncreation.\n\n\n\n\nReturn\n: an object.\n\n\nArguments\n:\n    :   -   \nmodeltype\n: a string. This will either be\n            'classification' or 'regression'.\n        -   \ndf\n: a data frame. The data your model will be based on.\n        -   \npredictedcol\n: a string. Name of variable (or column)\n            that you want to predict.\n        -   \ngraincol\n: a string, defaults to None. Name of possible\n            GrainID column in your dataset. If specified, this column\n            will be removed, as it won't help the algorithm.\n        -   \nimpute\n: a boolean. Whether to impute by replacing NULLs\n            with column mean (for numeric columns) or column mode (for\n            categorical columns).\n        -   \ndebug\n: a boolean, defaults to False. If TRUE, console\n            output when comparing models is verbose for easier\n            debugging.\n        -   \nwindowcol\n: a string. Which column in the dataset denotes\n            which rows are test ('Y') or training ('N').\n\n\n\n\nExample code:\n\n\np = DeploySupervisedModel(modeltype='regression',\n                          df=df,\n                          graincol='PatientEncounterID',\n                          windowcol='InTestWindowFLG',\n                          predictedcol='LDLNBR',\n                          impute=True,\n                          debug=False)\n\n\n\n\nStep 3: Create and save the model\n\n\nThe \ndeploy\n creates the model and method makes predictions that are\npushed to a database.\n\n\n\n\nReturn\n: an object.\n\n\nArguments\n:\n    :   -   \nmethod\n: a string. If you choose random forest, use 'rf'.\n            If you choose to deploy the linear model, use 'linear'.\n        -   \ncores\n: an integer. Denotes how many of your processors\n            to use.\n        -   \nserver\n: a string. Which server are you pushing\n            predictions to?\n        -   \ndest_db_schema_table\n: a string. Which\n            database.schema.table are you pushing predictions to?\n        -   \ntrees\n: an integer, defaults to 200. Use only if working\n            with random forest. This denotes number of trees in the\n            forest.\n        -   \ndebug\n: a boolean, defaults to False. If TRUE, console\n            output when comparing models is verbose for easier\n            debugging.\n\n\n\n\nExample code:\n\n\np.deploy(method='rf',\n         cores=2,\n         server='localhost',\n         dest_db_schema_table='[SAM].[dbo].[HCPyDeployRegressionBASE]',\n         use_saved_model=False,\n         trees=200,\n         debug=False)\n\n\n\n\nFull example code\n\n\n```python\nfrom healthcareai import DeploySupervisedModel\nimport pandas as pd\nimport time\n\n\ndef main():\n\n\nt0 = time.time()\n\n# Load in data\n# CSV snippet for reading data into dataframe\ndf = pd.read_csv('healthcareai/tests/fixtures/HCPyDiabetesClinical.csv',\n                na_values=['None'])\n\n# SQL snippet for reading data into dataframe\n# import pyodbc\n# cnxn = pyodbc.connect(\"\"\"SERVER=localhost;\n#                          DRIVER={SQL Server Native Client 11.0};\n#                          Trusted_Connection=yes;\n#                          autocommit=True\"\"\")\n#\n# df = pd.read_sql(\n#     sql=\"\"\"SELECT *\n#            FROM [SAM].[dbo].[HCPyDiabetesClinical]\"\"\",\n#     con=cnxn)\n#\n# # Set None string to be None type\n# df.replace(['None'],[None],inplace=True)\n\n# Look at data that's been pulled in\nprint(df.head())\nprint(df.dtypes)\n\n# Drop columns that won't help machine learning\ndf.drop('PatientID', axis=1, inplace=True)\n\np = DeploySupervisedModel(modeltype='regression',\n                          df=df,\n                          graincol='PatientEncounterID',\n                          windowcol='InTestWindowFLG',\n                          predictedcol='LDLNBR',\n                          impute=True,\n                          debug=False)\n\np.deploy(method='rf',\n         cores=2,\n         server='localhost',\n         dest_db_schema_table='[SAM].[dbo].[HCPyDeployRegressionBASE]',\n         use_saved_model=False,\n         trees=200,\n         debug=False)\n\nprint('\\nTime:\\n', time.time() - t0)\n\nif __name__ == \"__main__\":\n    main()\n\n\n\n``````", 
            "title": "Saving and deploying a model"
        }, 
        {
            "location": "/deploy/#deploying-and-saving-a-model", 
            "text": "", 
            "title": "Deploying and saving a model"
        }, 
        {
            "location": "/deploy/#what-is-deploysupervisedmodel", 
            "text": "This class lets one save a model (for recurrent use) and push\n    predictions to a database  One can do both classification (ie, predict Y/N) as well as\n    regression (ie, predict a numeric field).", 
            "title": "What is DeploySupervisedModel?"
        }, 
        {
            "location": "/deploy/#am-i-ready-for-model-deployment", 
            "text": "Only if you've already completed these steps:   You've found a model work that works well on your data  You've created a column called InTestWindowFLG (or something\n    similar), where 'Y' denotes rows that need a prediction and 'N' for\n    rows that train the model.  You've created the SQL table structure to receive predictions   For classification predictions:  CREATE TABLE [SAM].[dbo].[HCPyDeployClassificationBASE] (\n  [BindingID] [int] , \n  [BindingNM] [varchar] (255), \n  [LastLoadDTS] [datetime2] (7), \n  [PatientEncounterID] [decimal] (38, 0), --  change to your grain col\n  [PredictedProbNBR] [decimal] (38, 2),\n  [Factor1TXT] [varchar] (255), \n  [Factor2TXT] [varchar] (255), \n  [Factor3TXT] [varchar] (255))  For regression predictions:  CREATE TABLE [SAM].[dbo].[HCPyDeployRegressionBASE] (\n  [BindingID] [int], \n  [BindingNM] [varchar] (255), \n  [LastLoadDTS] [datetime2] (7), \n  [PatientEncounterID] [decimal] (38, 0), --  change to your grain col\n  [PredictedValueNBR] [decimal] (38, 2), \n  [Factor1TXT] [varchar] (255), \n  [Factor2TXT] [varchar] (255), \n  [Factor3TXT] [varchar] (255))", 
            "title": "Am I ready for model deployment?"
        }, 
        {
            "location": "/deploy/#step-1-pull-in-the-data", 
            "text": "For SQL:  import pyodbc\ncnxn = pyodbc.connect( SERVER=localhost;\n                        DRIVER={SQL Server Native Client 11.0};\n                        Trusted_Connection=yes;\n                        autocommit=True )\n\n df = pd.read_sql(\n     sql= SELECT\n            *\n            FROM [SAM].[dbo].[HCPyDiabetesClinical] ,\n     con=cnxn)\n\n\n # Handle missing data (if needed)\n df.replace(['None'],[None],inplace=True)  For CSV:  df = pd.read_csv('healthcareai/tests/fixtures/HCPyDiabetesClinical.csv',\n                 na_values=['None'])", 
            "title": "Step 1: Pull in the data"
        }, 
        {
            "location": "/deploy/#step-2-set-your-data-prep-parameters", 
            "text": "The  DeploySupervisedModel  cleans and prepares the data prior to model\ncreation.   Return : an object.  Arguments :\n    :   -    modeltype : a string. This will either be\n            'classification' or 'regression'.\n        -    df : a data frame. The data your model will be based on.\n        -    predictedcol : a string. Name of variable (or column)\n            that you want to predict.\n        -    graincol : a string, defaults to None. Name of possible\n            GrainID column in your dataset. If specified, this column\n            will be removed, as it won't help the algorithm.\n        -    impute : a boolean. Whether to impute by replacing NULLs\n            with column mean (for numeric columns) or column mode (for\n            categorical columns).\n        -    debug : a boolean, defaults to False. If TRUE, console\n            output when comparing models is verbose for easier\n            debugging.\n        -    windowcol : a string. Which column in the dataset denotes\n            which rows are test ('Y') or training ('N').   Example code:  p = DeploySupervisedModel(modeltype='regression',\n                          df=df,\n                          graincol='PatientEncounterID',\n                          windowcol='InTestWindowFLG',\n                          predictedcol='LDLNBR',\n                          impute=True,\n                          debug=False)", 
            "title": "Step 2: Set your data-prep parameters"
        }, 
        {
            "location": "/deploy/#step-3-create-and-save-the-model", 
            "text": "The  deploy  creates the model and method makes predictions that are\npushed to a database.   Return : an object.  Arguments :\n    :   -    method : a string. If you choose random forest, use 'rf'.\n            If you choose to deploy the linear model, use 'linear'.\n        -    cores : an integer. Denotes how many of your processors\n            to use.\n        -    server : a string. Which server are you pushing\n            predictions to?\n        -    dest_db_schema_table : a string. Which\n            database.schema.table are you pushing predictions to?\n        -    trees : an integer, defaults to 200. Use only if working\n            with random forest. This denotes number of trees in the\n            forest.\n        -    debug : a boolean, defaults to False. If TRUE, console\n            output when comparing models is verbose for easier\n            debugging.   Example code:  p.deploy(method='rf',\n         cores=2,\n         server='localhost',\n         dest_db_schema_table='[SAM].[dbo].[HCPyDeployRegressionBASE]',\n         use_saved_model=False,\n         trees=200,\n         debug=False)", 
            "title": "Step 3: Create and save the model"
        }, 
        {
            "location": "/deploy/#full-example-code", 
            "text": "```python\nfrom healthcareai import DeploySupervisedModel\nimport pandas as pd\nimport time  def main():  t0 = time.time()\n\n# Load in data\n# CSV snippet for reading data into dataframe\ndf = pd.read_csv('healthcareai/tests/fixtures/HCPyDiabetesClinical.csv',\n                na_values=['None'])\n\n# SQL snippet for reading data into dataframe\n# import pyodbc\n# cnxn = pyodbc.connect(\"\"\"SERVER=localhost;\n#                          DRIVER={SQL Server Native Client 11.0};\n#                          Trusted_Connection=yes;\n#                          autocommit=True\"\"\")\n#\n# df = pd.read_sql(\n#     sql=\"\"\"SELECT *\n#            FROM [SAM].[dbo].[HCPyDiabetesClinical]\"\"\",\n#     con=cnxn)\n#\n# # Set None string to be None type\n# df.replace(['None'],[None],inplace=True)\n\n# Look at data that's been pulled in\nprint(df.head())\nprint(df.dtypes)\n\n# Drop columns that won't help machine learning\ndf.drop('PatientID', axis=1, inplace=True)\n\np = DeploySupervisedModel(modeltype='regression',\n                          df=df,\n                          graincol='PatientEncounterID',\n                          windowcol='InTestWindowFLG',\n                          predictedcol='LDLNBR',\n                          impute=True,\n                          debug=False)\n\np.deploy(method='rf',\n         cores=2,\n         server='localhost',\n         dest_db_schema_table='[SAM].[dbo].[HCPyDeployRegressionBASE]',\n         use_saved_model=False,\n         trees=200,\n         debug=False)\n\nprint('\\nTime:\\n', time.time() - t0)\n\nif __name__ == \"__main__\":\n    main()  ``````", 
            "title": "Full example code"
        }, 
        {
            "location": "/compile/", 
            "text": "Compiling Python files to an exe\n\n\nWhy might I want to do this?\n\n\nNote: this is optional to model deployment. When working in with\nproduction environments, occasionally there are machines that one has to\nkeep relatively pure. In other words, perhaps you don't want to install\na Python (or more specifically, a Python interpreter) on that machine.\n\n\nBut what if you want to run a Python-based predictive model on that same\nmachine, and tie it into nightly ETL processes? That's why you'd want to\ncompile your .py file (which runs your model, for example) to an exe--if\nyou're using Windows--such that it's the only thing you place on the\nmachine that you want to keep pure. If you're using a OS X, one can\n\ncompile to an .app file\n.\n\n\nHow does this relate to healthcare.ai?\n\n\nAfter you've been able to \ndeploy\n\npredictions from your model back to SQL Server, you may want to compile\nyour .py file to an exe.\n\n\nThe workflow of saving and compiling a model to exe\n\n\n1)  Train and save your model by running your\n    \ndeploy\n .py file with the\n    \nuse_saved_model=False\n argument, such that two pkl files are\n    created\n2)  checked that you can run the model from from the pkl files, by\n    setting \nuse_saved_model=True\n and running your .py script again\n3)  Note that you should see more rows pushed to SQL Server for 1) and\n    2). If you didn't see new rows, something is wrong--fix your\n    deploy.py file before proceeding.\n4)  If you did see new rows inserted into the database, leave\n    \nuse_saved_model=True\n in your script and do the following in\n    PowerShell\n\n\n-   Install pyinstaller via\n    `conda install -c acellera pyinstaller=3.2.3`\n-   Then run\n\n\n\npyinstaller.exe --noconfirm --log-level=WARN --clean --nowindow --hidden-import=sklearn.tree._utils --name name_of_executable \nC:\\Users\\name\\deploy_script.py\n --distpath \nC:\\Users\\name\\compiled_model_folder\n \n# Copy pkl files (that represent the model) into exe directory just created\nxcopy \nC:\\Users\\name\\working_directory\n*.pkl \nC:\\Users\\name\\compiled_model_folder\n /Y", 
            "title": "Compiling python files to an executable"
        }, 
        {
            "location": "/compile/#compiling-python-files-to-an-exe", 
            "text": "", 
            "title": "Compiling Python files to an exe"
        }, 
        {
            "location": "/compile/#why-might-i-want-to-do-this", 
            "text": "Note: this is optional to model deployment. When working in with\nproduction environments, occasionally there are machines that one has to\nkeep relatively pure. In other words, perhaps you don't want to install\na Python (or more specifically, a Python interpreter) on that machine.  But what if you want to run a Python-based predictive model on that same\nmachine, and tie it into nightly ETL processes? That's why you'd want to\ncompile your .py file (which runs your model, for example) to an exe--if\nyou're using Windows--such that it's the only thing you place on the\nmachine that you want to keep pure. If you're using a OS X, one can compile to an .app file .", 
            "title": "Why might I want to do this?"
        }, 
        {
            "location": "/compile/#how-does-this-relate-to-healthcareai", 
            "text": "After you've been able to  deploy \npredictions from your model back to SQL Server, you may want to compile\nyour .py file to an exe.", 
            "title": "How does this relate to healthcare.ai?"
        }, 
        {
            "location": "/compile/#the-workflow-of-saving-and-compiling-a-model-to-exe", 
            "text": "1)  Train and save your model by running your\n     deploy  .py file with the\n     use_saved_model=False  argument, such that two pkl files are\n    created\n2)  checked that you can run the model from from the pkl files, by\n    setting  use_saved_model=True  and running your .py script again\n3)  Note that you should see more rows pushed to SQL Server for 1) and\n    2). If you didn't see new rows, something is wrong--fix your\n    deploy.py file before proceeding.\n4)  If you did see new rows inserted into the database, leave\n     use_saved_model=True  in your script and do the following in\n    PowerShell  -   Install pyinstaller via\n    `conda install -c acellera pyinstaller=3.2.3`\n-   Then run  pyinstaller.exe --noconfirm --log-level=WARN --clean --nowindow --hidden-import=sklearn.tree._utils --name name_of_executable  C:\\Users\\name\\deploy_script.py  --distpath  C:\\Users\\name\\compiled_model_folder  \n# Copy pkl files (that represent the model) into exe directory just created\nxcopy  C:\\Users\\name\\working_directory *.pkl  C:\\Users\\name\\compiled_model_folder  /Y", 
            "title": "The workflow of saving and compiling a model to exe"
        }
    ]
}