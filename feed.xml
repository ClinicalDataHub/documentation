<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xml" href="http://healthcare.ai/feed.xslt.xml"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.3.1">Jekyll</generator><link href="http://healthcare.ai/feed.xml" rel="self" type="application/atom+xml" /><link href="http://healthcare.ai/" rel="alternate" type="text/html" /><updated>2017-01-30T09:58:36-07:00</updated><id>http://healthcare.ai//</id><title type="html">healthcare.ai</title><entry><title type="html">How should you divide your data?</title><link href="http://healthcare.ai/blog/2017/01/26/training-testing/" rel="alternate" type="text/html" title="How should you divide your data?" /><published>2017-01-26T03:00:00-07:00</published><updated>2017-01-26T03:00:00-07:00</updated><id>http://healthcare.ai/blog/2017/01/26/training-testing</id><content type="html" xml:base="http://healthcare.ai/blog/2017/01/26/training-testing/">&lt;p&gt;At the most basic level, Machine Learning (ML) is a category of algorithms that learn from historical data and generalize to future data. Having good data is becoming more and more important to successful organizations today. It’s almost &lt;a href=&quot;http://www.nytimes.com/2012/02/12/sunday-review/big-datas-impact-in-the-world.html&quot;&gt;becoming a form of currency&lt;/a&gt;. But having access to big data is only the first step. Using it effectively is another matter entirely. Healthcare organizations have collected data for years, but data will always be a finite resource. This post seeks to help you decide how to best allocate your data resource for ML training, testing, and “in-the-wild” evaluation.&lt;/p&gt;

&lt;p&gt;When developing or training an ML model, you are trying to feed an algorithm as much data as possible to learn from. This is called the &lt;em&gt;training set&lt;/em&gt;. The model learns the patterns within that dataset and uses them to predict the outcome variable. When working on the training set, you will &lt;a href=&quot;http://healthcare.ai/blog/2017/01/24/feature-engineering/&quot;&gt;engineer features&lt;/a&gt;, &lt;a href=&quot;https://www.quora.com/What-are-hyperparameters-in-machine-learning&quot;&gt;tune hyperparameters&lt;/a&gt;, and select the &lt;a href=&quot;http://healthcare.ai/blog/2016/12/21/which-algorithms-are-in-healthcareai/&quot;&gt;ML algorithm&lt;/a&gt;. It might be possible to get your model to be perfectly &lt;a href=&quot;http://healthcare.ai/blog/2016/12/15/model-evaluation-using-roc-curves/&quot;&gt;accurate&lt;/a&gt; on the training set. But remember, that is not the ultimate goal! You want your model to be perfect on &lt;strong&gt;all&lt;/strong&gt; data. In other words, you want it to generalize well to new data.&lt;/p&gt;

&lt;p&gt;To generalize to new data, you must reserve some of your data for validation, or testing. A typical distribution is to use 60-80% of the data for training and the remaining for testing. If the model performs comparably well on the testing data, you can be fairly confident that the model will generalize well to new data. When splitting data into training and testing sets, it is ideal to have similarly distributed datasets in both groups. To do so, there are several things to keep in mind:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Randomize row numbers for training and testing. This avoids complications resulting from using separate blocks of time for training vs. testing. As an example, flu symptoms would be more common in the winter and you’d want those to appear at the same rate in both sets.&lt;/li&gt;
  &lt;li&gt;Keep positive and negative examples balanced. If you have a data set with 10% positive examples, try to divide those evenly. You don’t want your model to learn from only one type of example. For example, it is much more common for a patient to NOT be readmitted. &lt;a href=&quot;http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/&quot;&gt;Imbalanced classes&lt;/a&gt; are a common difficulty that we’ll cover more thoroughly in a future post.&lt;/li&gt;
  &lt;li&gt;Think about the distributions within individual columns and whether random sampling is likely to result in similarly distributed training and test sets. If it won’t, you might need to manually sample.
In practice, a good first step is to randomly assign groups and &lt;a href=&quot;http://healthcare.ai/blog/2016/12/15/model-evaluation-using-roc-curves/&quot;&gt;evaluate your model’s performance&lt;/a&gt; on 80% training and 20% testing sets. If the model is highly accurate across both data sets, it is ready to move on to the &lt;em&gt;deployment&lt;/em&gt; step.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the deployment step, the model is put into production and left to make new predictions on new data examples. We sometimes refer to this period as “in-the-wild” testing, where the model is deployed on the servers and is interacting with real data. We aren’t using the model to inform decisions yet, but it’s in the last stage of evaluations. It’s worth noting that we are not changing the model here, but using the saved model from development. In this phase, we are looking to see that the performance is the same in the wild as it was in development training and testing. If it’s not, the model must be debugged for issues like &lt;a href=&quot;http://healthcare.ai/blog/2017/01/06/data-leakage-in-healthcare-machine-learning/&quot;&gt;data leakage&lt;/a&gt; or &lt;a href=&quot;http://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/&quot;&gt;overfitting&lt;/a&gt;. The length of time required for this step depends on the target variable. For example, a 30-day readmission model will require at least 30 days of in-the-wild testing. If testing in the wild is successful, the model is ready to move into production and help guide decisions.&lt;/p&gt;

&lt;p&gt;Building an ML model is often a difficult process. A large dataset is the first step, but it must be cleaned and prepared. The model must be trained while keeping many small things in mind. It can be a tiresome process of guess and check, but experience with ML and domain knowledge of the data can speed things up. Additionally, many of these steps, such as randomizing data, can be automated. One focus of &lt;a href=&quot;http://healthcare.ai/&quot;&gt;healthcare.ai&lt;/a&gt; is helping to reduce the number of things a user has to keep track of while model building.&lt;/p&gt;

&lt;p&gt;Hopefully this post helps you get the most out of your dataset, and you can use it to build models that generalize well to new data. As always, feel free to &lt;a href=&quot;http://healthcare.ai/contact.html&quot;&gt;reach out with questions&lt;/a&gt;, and thanks for reading.&lt;/p&gt;</content><author><name>Mike Mastanduno</name></author><category term="overview" /><summary type="html">This is an overview of training and testing data sets. And of ML models in development and deployment.</summary></entry><entry><title type="html">Feature engineering in healthcare machine learning</title><link href="http://healthcare.ai/blog/2017/01/24/feature-engineering/" rel="alternate" type="text/html" title="Feature engineering in healthcare machine learning" /><published>2017-01-24T03:00:00-07:00</published><updated>2017-01-24T03:00:00-07:00</updated><id>http://healthcare.ai/blog/2017/01/24/feature-engineering</id><content type="html" xml:base="http://healthcare.ai/blog/2017/01/24/feature-engineering/">&lt;p&gt;In previous blog posts, we’ve discussed specific &lt;a href=&quot;http://healthcare.ai/blog/2016/12/22/applications-of-healthcare-machine-learning/&quot;&gt;applications of machine learning (ML) in healthcare&lt;/a&gt; and the &lt;a href=&quot;http://healthcare.ai/blog/2016/12/21/which-algorithms-are-in-healthcareai/&quot;&gt;available algorithms in healthcare.ai&lt;/a&gt;. As you build an ML model, creating and selecting the right features can be just as foundationally important as matching the right algorithm with the right use case. In this post, we will discuss how domain knowledge of healthcare data can be used to create features that make your ML models more accurate and useful. This process is known as &lt;a href=&quot;https://en.wikipedia.org/wiki/Feature_engineering&quot;&gt;feature engineering&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Using an ML model off the shelf is easy but often ineffective. Feature engineering usually makes or breaks it. It’s the creative part of the process that builds the foundation for everything else. Many of the features we use in our ML models can be categorized as demographics, vitals, labs, medications, clinical events, healthcare utilization, visit details, and comorbidities. We can break these categories out more granularly into the specific features that are helpful to our ML model. From here, we often develop multiple transformations of a feature based on the underlying reasons that might inherently make that specific form of the feature more predictive—this is the engineering part.&lt;/p&gt;

&lt;p&gt;For example, a patient’s blood pressure could be a clinical event feature that is predictive of their hospital length of stay. However, there are a bunch of things you need to consider before arriving at a truly predictive feature: Should you separate systolic from diastolic? Create a binary feature, hypotension, or hypertension? Or continuous? When multiple records exist, do you use the highest values or the lowest? Earliest or latest? And so on. You might even need to get so specific as to create a binary (Yes/No) feature defined by the question, “Was the patient’s systolic blood pressure 140 mmHg or higher during the first 12 hours following admission to the hospital?” or a continuous feature defined as the “Highest diastolic blood pressure value within the first 24 hours of admission to the hospital.”&lt;/p&gt;

&lt;p&gt;For clarity’s sake, two additional examples of basic feature engineering that we use regularly are age and home address. A feature containing continuous age values could be helpful to the model on its own, or transformed into 10-year age groups or a binary variable identifying patients age 65 and older. An address can be broken out into its various components like city, state, and zip code, all of which can serve as proxies for helpful information that is not always available in the data, like socioeconomic status. We can also use &lt;a href=&quot;https://en.wikipedia.org/wiki/Geocoding&quot;&gt;geocoding&lt;/a&gt; to convert addresses into coordinates that can be plotted against relevant maps to pick up additional insight related to things like distance to a provider or local barriers to transportation.&lt;/p&gt;

&lt;p&gt;Clearly, you could come up with dozens of versions of a single feature, and some are going to work much better than others. The great thing about ML is that you can use your healthcare domain knowledge to pare down the relevant and potentially useful iterations of your feature, and then let the ML algorithm help isolate the most predictive features and transformations during final &lt;a href=&quot;https://en.wikipedia.org/wiki/Feature_selection&quot;&gt;feature selection&lt;/a&gt; (a related topic that we’ll dive into in an upcoming post). The ML algorithms in &lt;a href=&quot;http://healthcare.ai/&quot;&gt;healthcare.ai&lt;/a&gt; can help select the right versions, but you have to do the leg work to get them in there to try. Also, we covered this recently, but don’t forget about &lt;a href=&quot;http://healthcare.ai/blog/2017/01/06/data-leakage-in-healthcare-machine-learning/&quot;&gt;data leakage&lt;/a&gt; when creating features; you’ll need to make sure you consider your use case so that you don’t train the ML model using features that would not yet be available at your preferred time of prediction.&lt;/p&gt;

&lt;p&gt;Feature engineering is a ton of work and underscores the importance of data scientists and data architects having a combination of technical skills and deep domain knowledge. Some good news related to lightening the workload—we’ve already included a couple of feature engineering functions in healthcare.ai that can save a significant amount of time and effort transforming certain features.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://healthcare.ai/r/model-pre-processing/longitudinal-imputation/&quot;&gt;Longitudinal imputation&lt;/a&gt; works with longitudinal data to carry a value forward from a patient’s previous record to the fill in a NULL value in the most current record. An example might be using longitudinal imputation to pull a patient’s BMI forward from their previous visit to their current visit if their weight and height have not yet been recorded. Using this function appropriately can improve model accuracy by filling in data that might otherwise be left NULL or imputed with your dataset’s mean or mode for that feature.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://healthcare.ai/r/model-pre-processing/seasonality-handling/&quot;&gt;Seasonality handling&lt;/a&gt; transforms date-time columns, which are difficult for ML algorithms to handle, into their various components, ultimately treating them as separate features. Event dates, like date of admission, can hold a lot of helpful information for seasonality handling and proxying for other things that might not be well represented in the data. With minimal effort, you can use this function to test which component(s) of the admit date-time stamp like month, day of week, hour, etc., are most helpful to your model.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Automating feature engineering is difficult to do, especially considering the complexity of healthcare data and the types of healthcare ML problems we are attempting to solve. Deep domain knowledge and human intuition are very difficult to replicate. However, it’s a hot area of research and we’ll definitely continue to explore and post on advances in feature engineering. Algorithms for automatically generating features for relational data sets like the &lt;a href=&quot;http://groups.csail.mit.edu/EVO-DesignOpt/groupWebSite/uploads/Site/DSAA_DSM_2015.pdf&quot;&gt;Deep Feature Synthesis algorithm&lt;/a&gt; are becoming smarter and more dynamic every day. We look forward to incorporating new techniques and algorithms into healthcare.ai so that we can all focus our efforts on improving healthcare outcomes in new and exciting ways.&lt;/p&gt;

&lt;p&gt;Thanks for reading, and please &lt;a href=&quot;http://healthcare.ai/contact&quot;&gt;reach out&lt;/a&gt; with any questions or comments!&lt;/p&gt;</content><author><name>Taylor Larsen</name></author><category term="overview" /><summary type="html">This blog will discuss how domain knowledge of healthcare data can be used to create features that make ML models more accurate and useful</summary></entry><entry><title type="html">Survey of deep learning in radiology</title><link href="http://healthcare.ai/blog/2017/01/19/survey-of-deep-learning-in-radiology/" rel="alternate" type="text/html" title="Survey of deep learning in radiology" /><published>2017-01-19T16:32:11-07:00</published><updated>2017-01-19T16:32:11-07:00</updated><id>http://healthcare.ai/blog/2017/01/19/survey-of-deep-learning-in-radiology</id><content type="html" xml:base="http://healthcare.ai/blog/2017/01/19/survey-of-deep-learning-in-radiology/">&lt;p&gt;This blog has been talking a lot about Machine Learning (ML) with regard to tabular data. That makes sense because predictive algorithms based on tabular data are often easy to implement and have a lot of potential to improve outcomes. Also, we have access to a lot of tabular data from the EHR.  However, ML is capable of doing a lot more than predicting probabilities on tabular data, and there are incredible opportunities in other areas of healthcare. One in particular is in Radiology and Pathology departments. These departments generate tabular data, but their bread and butter is image data. Beth Israel Deaconess Medical Center (Harvard), for instance, generates approximately 20 terabytes of image data per year (vs. 1 TB text data) &lt;a href=&quot;http://geekdoctor.blogspot.com/2011/04/cost-of-storing-patient-records.html&quot;&gt;source&lt;/a&gt;. That’s a lot of data to potentially use!&lt;/p&gt;

&lt;p&gt;With all the talk around deep learning lately, it would be hard for an ML group to avoid at least discussing whether or not it would be practical to develop our own applications. While deep learning is absolutely a buzz word, it truely does present a number of possibilities for future innovations. In only a handful of years, deep learning will &lt;a href=&quot;https://www.tesla.com/autopilot&quot;&gt;driving our cars&lt;/a&gt;, doing &lt;a href=&quot;http://www.nytimes.com/2016/12/14/magazine/the-great-ai-awakening.html?smid=pl-share&amp;amp;_r=0&quot;&gt;real-time translation of spoken language&lt;/a&gt;, allowing you to &lt;a href=&quot;https://www.ditto.com/&quot;&gt;virtually try on glasses online&lt;/a&gt;, and many other amazing things that we haven’t even imagined yet. With this kind of limitless potential, it isn’t hard to imagine an opportunity for computers to read medical images, as outlined in this paper from the &lt;a href=&quot;http://www.nejm.org/doi/full/10.1056/NEJMp1606181&quot;&gt;New England Journal of Medicine&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One of the great things about working on &lt;a href=&quot;http://healthcare.ai&quot;&gt;healthcare.ai&lt;/a&gt; is the opportunity to plan and shape &lt;a href=&quot;http://healthcare.ai/blog/2016/12/21/which-algorithms-are-in-healthcareai/&quot;&gt;what the package is capable of&lt;/a&gt;. There are things that we are working towards in the near future, like unsupervised learning, and there is functionality that is still not mainstream and will require a more concentrated research effort for us to be able to implement. &lt;strong&gt;The purpose of this post is to try to provide a survey of machine learning on medical imaging, and where the lowest hanging fruit might be.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;One area, &lt;a href=&quot;https://www.cancer.gov/types/breast/mammograms-fact-sheet#q1&quot;&gt;mammographic screening&lt;/a&gt;, is a particularly promising application of deep learning. Current guidelines recommend annual or biennial breast cancer screening with mammography for women over 40 or 50 (depending on the guideline). This means we do a lot of expensive screening, and it’s not always effective. Deep learning could help improve the effectiveness of that screening to improve outcomes and reduce costs. Take a look at &lt;a href=&quot;http://ashevillegynecologywellness.com/wp-content/uploads/2016/05/MammoGram-Seriesshow.jpg&quot;&gt;these images&lt;/a&gt;. Even if you are not a trained radiologist, you are probably able to make medically relevant observations about them. The normal mammogram looks rather indistinct. There are brighter areas and darker areas, but they are mostly &lt;a href=&quot;http://www.facingourrisk.org/our-role-and-impact/advocacy/documents/breast-screening-comparison-chart.pdf&quot;&gt;consistent&lt;/a&gt;. The second image from the left has a large, round, and uniformly bright spot, almost a sure sign of a cyst. Finally, the cancer image has a very bright spot that seems to have tentacles extending from a central structure. While real images can be extremely subtle and difficult to read (that’s why you need an MD!), a radiologist would perform the same steps you just did. They make observations about the image, relate their findings to their medical knowledge, and make a diagnosis.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/radPost_mammo.png&quot; alt=&quot;Example Mammograms&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As it turns out, &lt;a href=&quot;http://www.nature.com/nature/journal/v521/n7553/full/nature14539.html&quot;&gt;deep learning algorithms&lt;/a&gt; excel at the same kind of analysis and pattern recognition that a radiologist does. The algorithms will examine thousands of images of every type and eventually learn how to distinguish them based on different sized sections of the image. There is potential to see patterns that would elude even best radiologists, detect exquisitely specific changes in a single person’s history, and totally transform radiology. This application could help to treat breast cancer more effectively, at lower cost, with fewer resources.
Of course, there have already been efforts at individual academic medical centers in mammographic screening. Big breakthroughs in breast imaging are just starting to come out in the high-impact journals.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Recently, &lt;a href=&quot;http://www.nature.com/articles/srep27327&quot;&gt;Wang et al.&lt;/a&gt; were able to detect &lt;a href=&quot;http://www.mayoclinic.org/symptoms/breast-calcifications/basics/definition/sym-20050834&quot;&gt;microcalcifications&lt;/a&gt; in mammograms, an effective early indicator of breast cancer. They used a data set of approximately 1200 images to train a Stacked Auto-Encoder deep learning architecture, and were able to identify microcalcifications with an &lt;a href=&quot;http://healthcare.ai/blog/2016/12/15/model-evaluation-using-roc-curves/&quot;&gt;AUC&lt;/a&gt; of 0.87.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In another study, &lt;a href=&quot;http://www.nature.com/articles/srep24454&quot;&gt;Cheng et al.&lt;/a&gt; used a Stacked Denoising Auto-Encoder to differentiate malignant breast lesions from benign in 550 &lt;a href=&quot;http://www.cancer.org/cancer/breast-cancer/screening-tests-and-early-detection/breast-ultrasound.html&quot;&gt;ultrasound&lt;/a&gt; images. They achieved an AUC of 0.90.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Finally, &lt;a href=&quot;https://arxiv.org/abs/1612.00542&quot;&gt;Levy et al.&lt;/a&gt; trained several existing Convolutional Neural Network (CNN) architectures to classify pre-labeled regions from 1800 mammograms. Their GoogLeNet CNN was able to distinguish malignant from benign with precision of 0.92 and recall of 0.93.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If we were to move forward with a deep learning model for breast imaging, reproducing one of these studies would be a good starting point. Screening mammograms are probably the best place to start, due to their high volume in healthcare. In addition to breast imaging, &lt;a href=&quot;http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7463094&quot;&gt;this excellent review&lt;/a&gt; points out several other promising areas to begin. Additional promising areas are in lung cancer screening from CT images and automated tissue labeling of brain MRI. In lung cancer screening and automatic brain segmentation:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/ftp/arxiv/papers/1611/1611.06651.pdf&quot;&gt;Yang et al.&lt;/a&gt; employed a CNN to classify known lung nodules as either malignant or benign from 4 separate data sets. Some of their models failed to generalize well, but others could achieve extremely high classification accuracy on the validation set.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In the same paper as their breast study, &lt;a href=&quot;http://www.nature.com/articles/srep24454&quot;&gt;Cheng et al.&lt;/a&gt; classified 1400 lung nodules from chest CT images. They saw AUC as high as 0.98 depending on the algorithm configuration.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S1361841516300330&quot;&gt;Havaei et al.&lt;/a&gt; present their state of the art segmentation of glioblastoma brain tumors from MRI images. They use a CNN to segment a competition data set with practical speed (0.5 to 3 minutes) and high accuracy.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It would be crazy to try to cover every bit of research in this post. There are countless studies to cover beyond those discussed here, plus annual conferences such as &lt;a href=&quot;https://nips.cc/&quot;&gt;NIPS&lt;/a&gt; and &lt;a href=&quot;https://2017.icml.cc/&quot;&gt;ICML&lt;/a&gt;. However, it would be worth mentioning a few areas of research from the private sector.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Google DeepMind &lt;a href=&quot;https://deepmind.com/applied/deepmind-health/&quot;&gt;recently announced a health initiative&lt;/a&gt; and has been working to identify diabetic retinopathy from images of the eye.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The San Francisco-based start-up, &lt;a href=&quot;http://www.enlitic.com/&quot;&gt;Enlitic&lt;/a&gt;, works to develop deep learning methods for the use cases above and has partnered with several hospitals already.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://siris-medical.com/&quot;&gt;Siris Medical&lt;/a&gt; works to use past patient data to automate radiation treatment planning and brain segmentation.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Finally, many of the data sets that were used in the studies mentioned above are open source and freely available.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.visceral.eu/&quot;&gt;Visceral&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://image-net.org/&quot;&gt;ImageNet&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.kaggle.com/c/data-science-bowl-2017&quot;&gt;Kaggle Data Science Bowl&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://grand-challenge.org/All_Challenges/&quot;&gt;Grand Challenge&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://imaging.cancer.gov/programsandresources/informationsystems/lidc&quot;&gt;Lung Image Database Consortium&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://braintumorsegmentation.org/&quot;&gt;Multimodal Brain Tumor Segmentation Challenge&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Breast screening, lung screening, and brain segmentation are the some of the most popular and promising applications of deep learning in healthcare today. Early research in these areas has shown encouraging results, and there is a lot of effort toward advancements. Furthermore, these areas have the potential to benefit a lot of patients as they include common diseases, treatments, and procedures. It’s an exciting time to be in healthcare machine learning, and we look forward to implementing deep learning into our package.   Thanks for reading, and please feel free to &lt;a href=&quot;http://healthcare.ai/contact&quot;&gt;reach out&lt;/a&gt; with questions!&lt;/p&gt;</content><author><name>Mike Mastanduno</name></author><category term="literature" /><summary type="html">This blog will surveys recent research in deep learning and radiology.</summary></entry><entry><title type="html">Using R for healthcare data analysis</title><link href="http://healthcare.ai/blog/2017/01/17/using-r-for-data-analysis/" rel="alternate" type="text/html" title="Using R for healthcare data analysis" /><published>2017-01-17T11:12:11-07:00</published><updated>2017-01-17T11:12:11-07:00</updated><id>http://healthcare.ai/blog/2017/01/17/using-r-for-data-analysis</id><content type="html" xml:base="http://healthcare.ai/blog/2017/01/17/using-r-for-data-analysis/">&lt;p&gt;When working with data in healthcare, business intelligence (BI) folks often turn to tools like Excel, SSMS, Tableau, and Qlik. Typically, multiple tools will be used when analyzing a dataset. Sometimes the analyst will use Excel to look at the data, get a sense for how the columns are distributed, perhaps make a histogram or scatterplot. Often, analysts will later turn to Qlik and/or Tableau to provide an interactive app, often hosted on a dedicated server so folks in other departments can explore the same data. In this same process, the analyst or data architect may start by querying the database in SSMS to do some simple counts and group bys in an effort to understand the data at a high-level.&lt;/p&gt;

&lt;p&gt;Is that split workflow the most efficient way of doing things? Is there a tool that might provide a streamlined analysis, both providing a way to understand the high-level, as well as offering interactive apps for entire departments? While the tools mentioned above are certainly fantastic, we feel that &lt;strong&gt;R&lt;/strong&gt; could help make life a lot easier for BI professionals.&lt;/p&gt;

&lt;p&gt;While we don’t want to oversell its abilities, think of how often analysts turn to the above tools to do things like:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Understanding how data is distributed&lt;/li&gt;
  &lt;li&gt;Finding how particular columns are correlated&lt;/li&gt;
  &lt;li&gt;Offering pivot tables&lt;/li&gt;
  &lt;li&gt;Making histograms or scatterplots&lt;/li&gt;
  &lt;li&gt;Grouping by a column of interest and plotting a trend&lt;/li&gt;
  &lt;li&gt;Calculating statistics (like standard deviations, t-tests, quantiles)&lt;/li&gt;
  &lt;li&gt;Creating interactive visualizations for others&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You may be surprised to hear that R can also do those things, and do them &lt;em&gt;well&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;If you’re using Excel for things like financial modeling, and/or have the need to input data frequently, then moving to R won’t make sense. We’ll be the first to say that Excel can be a super effective tool.&lt;/p&gt;

&lt;p&gt;But, if you’re often doing analysis using the tools mentioned above, we’re excited to help you see what R can do. Besides the above, here are other benefits of R compared to Excel/Qlik:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Lends itself to source control&lt;/li&gt;
  &lt;li&gt;Makes your work easily reproducible&lt;/li&gt;
  &lt;li&gt;Enables you to tell a data story (combining process and presentation in a notebook)&lt;/li&gt;
  &lt;li&gt;Allows one to more easily find and fix errors&lt;/li&gt;
  &lt;li&gt;Makes it easy to work on very large datasets&lt;/li&gt;
  &lt;li&gt;Offers machine learning&lt;/li&gt;
  &lt;li&gt;It’s free&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We’ll try to illustrate the analytical capabilities of R in a series of blog posts. Each blog post will contain an R notebook that’ll have explanations, R code, and R plots to help you get stated. &lt;a href=&quot;http://healthcare.ai/notebooks/IntroHealthDataAnalysisInR.nb.html&quot;&gt;Here’s the first notebook in this series&lt;/a&gt;. Enjoy!&lt;/p&gt;</content><author><name>Levi Thatcher</name></author><category term="analysis" /><summary type="html">When working with data in healthcare, business intelligence (BI) folks often turn to tools like Excel, SSMS, Tableau, and Qlik. Typically, multiple tools will be used when analyzing a dataset. Sometimes the analyst will use Excel to look at the data, get a sense for how the columns are distributed, perhaps make a histogram or scatterplot. Often, analysts will later turn to Qlik and/or Tableau to provide an interactive app, often hosted on a dedicated server so folks in other departments can explore the same data. In this same process, the analyst or data architect may start by querying the database in SSMS to do some simple counts and group bys in an effort to understand the data at a high-level.</summary></entry><entry><title type="html">Contributing to open source software development using Github</title><link href="http://healthcare.ai/blog/2017/01/12/open-source-and-git/" rel="alternate" type="text/html" title="Contributing to open source software development using Github" /><published>2017-01-12T01:32:11-07:00</published><updated>2017-01-12T01:32:11-07:00</updated><id>http://healthcare.ai/blog/2017/01/12/open-source-and-git</id><content type="html" xml:base="http://healthcare.ai/blog/2017/01/12/open-source-and-git/">&lt;p&gt;The purpose of this post is to help you become familiar with &lt;em&gt;Git&lt;/em&gt;, an essential part of contributing to &lt;a href=&quot;http://healthcare.ai&quot;&gt;healthcare.ai&lt;/a&gt;. Git is essentially a collaboration tool for software developers, and &lt;a href=&quot;http://github.com&quot;&gt;&lt;em&gt;Github&lt;/em&gt;&lt;/a&gt; is the accompanying online storage platform. If you have been reading about healthcare.ai, you probably know that it is an &lt;a href=&quot;http://healthcare.ai/#why&quot;&gt;&lt;em&gt;open source&lt;/em&gt; software package&lt;/a&gt;. Open source means that we aren’t hiding anything from our users. They can use the package, view the contents, and modify the package for their particular needs. We chose to make healthcare.ai open source for two major reasons:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Anyone can contribute to its development.&lt;/strong&gt; When an open source package becomes popular, there could be hundreds of people working on making it better!&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;The rising tide will raise all boats.&lt;/strong&gt; We are trying to be a leader in healthcare machine learning, and hoping that our efforts will be visible, benefit the community, and benefit patient care.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;As our team (and number of contributors) grows, it doesn’t make sense to share our code using email attachments. We make thousands of changes on hundreds of files. Instead, we use Git. Git is an industry standard service that makes it easy for large teams to collaborate on code, keep files safe from unwanted changes through &lt;em&gt;version control&lt;/em&gt;, and facilitate code review before changes are published.&lt;/p&gt;

&lt;p&gt;The idea of Git is pretty easy to follow, but the vocabulary can be a little confusing at first. There are &lt;a href=&quot;https://guides.github.com/introduction/flow/&quot;&gt;many&lt;/a&gt; &lt;a href=&quot;http://git.huit.harvard.edu/guide/&quot;&gt;great&lt;/a&gt; &lt;a href=&quot;https://guides.github.com/activities/hello-world/&quot;&gt;resources&lt;/a&gt; about Git online, but sometimes they are too basic for specific issues, or too complicated and lacking explanation. Hopefully you find the ideas below to be both useful and informative.&lt;/p&gt;

&lt;p&gt;Imagine that you are writing a paper. You write some, save the file: “myPaper_version1.doc.” You write more, save version 2, version 3… Essentially, this is what Git is doing. The codebase, or repository, is written line by line, and each change can be stored as a &lt;em&gt;commit&lt;/em&gt;. The commits flow linearly, and if you don’t like the latest changes, you can roll back to the previous commit. This &lt;a href=&quot;http://rogerdudler.github.io/git-guide/files/git_cheat_sheet.pdf&quot;&gt;excellent cheat sheet shows that process&lt;/a&gt;, where each circle represents a commit.&lt;/p&gt;

&lt;p&gt;I’ll focus on explaining five topics that are likely to help you collaborate.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Local vs source&lt;br /&gt;
A code repository lives at &lt;a href=&quot;http://github.com&quot;&gt;www.github.com&lt;/a&gt;, and you’d like to work on it. The &lt;em&gt;master&lt;/em&gt; source is online. You need to &lt;em&gt;clone&lt;/em&gt; or &lt;em&gt;fork&lt;/em&gt; the repo to create a local copy on your computer. You can make improvements, commit them, and document each change. Verify that your code is working, then, they can be &lt;em&gt;merged&lt;/em&gt; into the source copy.&lt;/li&gt;
  &lt;li&gt;Pushing and Pulling&lt;br /&gt;
When you are ready to submit your changes to the master, you must first &lt;em&gt;pull&lt;/em&gt; changes from the master source to your local copy. This ensures that you have the latest changes from the master in your local copy. Then you can &lt;em&gt;push&lt;/em&gt; your changes up to the online master. If you take a few weeks away from the code, make sure you pull the latest changes into your local copy before starting your work.
    &lt;ul&gt;
      &lt;li&gt;Pull changes from the master source to your local copy: &lt;code class=&quot;highlighter-rouge&quot;&gt;git pull&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Push your local changes to the online master: &lt;code class=&quot;highlighter-rouge&quot;&gt;git push&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Branches&lt;br /&gt;
&lt;a href=&quot;http://github.com/HealthCatalystSLC/healthcareai-r/branches/&quot;&gt;&lt;em&gt;Branches&lt;/em&gt;&lt;/a&gt; are used to help keep large changes, feature additions, etc. separate from the master source. They allow you to “break the code to fix it” without worrying that you are going to ruin the master. If you create a topic branch to work in, you now have two separate local copies: your local master, and your local branch. You can make ongoing changes to the code in your branch, then switch back to the master to actually use code that you know is working.
    &lt;ul&gt;
      &lt;li&gt;Create a new topic branch or switch to an existing topic branch: &lt;code class=&quot;highlighter-rouge&quot;&gt;git checkout -b nameofbranch&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Merging&lt;br /&gt;
When the topic branch you’ve been developing is done, documented, and functional, it’s ready to be merged back into the master branch. Again, update your local master, as other people could have been working on the code while you were. Merge the local master into your local branch (the ordering can be disputed, but this is how we do it at healthcare.ai), allowing you to test for functionality with all the latest changes. Finally, push the local branch up to the server and ask for review.
    &lt;ul&gt;
      &lt;li&gt;Check out the latest online master and merge into the local topic branch: &lt;code class=&quot;highlighter-rouge&quot;&gt;git merge origin/master&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Make sure it all still works!&lt;/li&gt;
      &lt;li&gt;Push the local branch to the server for review: &lt;code class=&quot;highlighter-rouge&quot;&gt;git push&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pull Requests&lt;br /&gt;
After pushing a completed topic branch up to the server, the &lt;em&gt;pull request&lt;/em&gt; acts as a request for code review. The term pull request &lt;del&gt;makes no sense to me&lt;/del&gt; &lt;a href=&quot;https://www.quora.com/GitHub-Why-is-the-pull-request-called-pull-request&quot;&gt;Got it!&lt;/a&gt; Another developer will look through your changes and documentation, ask for revisions, and eventually approve the pull request. After this happens, the branch will be merged into the online master. Anyone who clones the master will now get your changes, and the branch can be deleted.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There is a lot of vocabulary in this post, but we hope that it’s helpful to see these things defined in context of how they are used. Seasoned developers forget that Git language can be hard to interpret since it’s such an important part of their everyday work. The truth is, it’s a barrier to entry for the casual contributor. However, it’s extremely important for the health of a large code project and the team that works on it.&lt;/p&gt;

&lt;p&gt;If you’ve become motivated to get down to business, make an account on &lt;a href=&quot;https://github.com/&quot;&gt;Github&lt;/a&gt;, &lt;a href=&quot;https://github.com/HealthCatalystSLC/healthcareai-r/blob/master/CONTRIBUTING.md#clone-healthcareai-r-repo&quot;&gt;clone our repo&lt;/a&gt;, and help us shape the future of healthcare machine learning! There are more detailed instructions in the &lt;a href=&quot;https://github.com/HealthCatalystSLC/healthcareai-r/blob/master/README.md&quot;&gt;readme&lt;/a&gt; and &lt;a href=&quot;https://github.com/HealthCatalystSLC/healthcareai-r/blob/master/CONTRIBUTING.md&quot;&gt;contributing&lt;/a&gt; files, and you can feel free to &lt;a href=&quot;http://healthcare.ai/contact.html&quot;&gt;send questions&lt;/a&gt; our way.&lt;/p&gt;</content><author><name>Mike Mastanduno</name></author><category term="workflow" /><summary type="html">This blog will describe the motivation and workflow of Git version control</summary></entry><entry><title type="html">Know your business question: A focus on readmissions</title><link href="http://healthcare.ai/blog/2017/01/11/know-your-business-question-a-focus-on-readmissions/" rel="alternate" type="text/html" title="Know your business question: A focus on readmissions" /><published>2017-01-11T21:00:00-07:00</published><updated>2017-01-11T21:00:00-07:00</updated><id>http://healthcare.ai/blog/2017/01/11/know-your-business-question-a-focus-on-readmissions</id><content type="html" xml:base="http://healthcare.ai/blog/2017/01/11/know-your-business-question-a-focus-on-readmissions/">&lt;p&gt;As time goes on, we will not only discuss healthcare machine learning (ML) and health in the US at a high level, but also specific ways ML might help drive outcomes improvements. Many health systems are working on reducing their readmission rate—which is often considered a measure of quality of care and can be tied to penalties. For  hospital systems progressing toward ML for readmissions—or any measure—the first step is to identify your most important business questions; the next step is creating a suitable dataset to create the model. There are often several points where business logic dictates decisions related to the dataset and whether one or multiple models are needed to help with a specific process. That’s certainly the case when creating readmission risk models.&lt;/p&gt;

&lt;p&gt;Readmission risk models improve patient quality of life and decrease mortality by providing extra care or surveillance to high-risk patients. Implementing a readmission risk model could serve two different purposes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Identifying high-risk &lt;em&gt;observational&lt;/em&gt; and &lt;em&gt;inpatient&lt;/em&gt; patients as soon after their admission as possible to answer this question: &lt;em&gt;Which in-hospital patients are most at risk for readmission?&lt;/em&gt; By answering this question, doctors, nurses, and in-hospital staff can intervene to try to lower a patient’s readmission risk.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Identifying high-risk &lt;em&gt;discharged&lt;/em&gt; patients as soon after their discharge as possible to answer this question: &lt;em&gt;Which discharged patients are most at risk of readmission?&lt;/em&gt; By answering this question, hospital support staff and transitional services can intervene to try to lower a patient’s readmission risk.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now, you might think, “Those are the same use case: they both predict readmissions, even sometimes for the same patients.” But remember, an ML model is only valuable if it provides actionable insight. Nurses are in the optimal position to help when the patient is in the hospital. Furthermore, as we &lt;a href=&quot;http://healthcare.ai/blog/2017/01/06/data-leakage-in-healthcare-machine-learning/&quot;&gt;discussed at length&lt;/a&gt; last week, the data sources for these two use cases are very different. The type and amount of information available at discharge is different from what is available at admission. The best ML models are built custom to a specific dataset and use case. One risk model is not sufficient to answer both questions, and accuracy would almost certainly be compromised if they were naively combined. Though similar, these questions need models that relate to different types of patients and are targeted toward different interventions. Under the hood of the models, we need to use different datasets (to avoid &lt;a href=&quot;http://healthcare.ai/blog/2017/01/06/data-leakage-in-healthcare-machine-learning/&quot;&gt;data leakage&lt;/a&gt;)—and maybe even different algorithms. The best ML model will always be built to answer a specific question, tailored to specific data, and targeted toward the most effective intervention.&lt;/p&gt;

&lt;p&gt;OK, so we know we need two models for readmission risk modeling. But to complicate things even more, we must keep in mind that the layman definition of readmission and the &lt;a href=&quot;https://www.cms.gov/Medicare/Medicare-Fee-for-Service-Payment/PhysicianFeedbackProgram/Downloads/2014-ACR-MIF.pdf&quot;&gt;CMS definition of readmission&lt;/a&gt; are also subtly different. We must base our outcome variable on a definition very similar to that of CMS because it is consistent with the way many hospital systems track and report outcomes, and the CMS definition of readmissions is ultimately the measure hospital systems are trying to affect. Knowing that definition is critical to building a model to address it.&lt;/p&gt;

&lt;p&gt;Per the CMS definition, patients in the hospital can be &lt;em&gt;emergency department&lt;/em&gt;, &lt;em&gt;observational&lt;/em&gt;, or &lt;em&gt;inpatient&lt;/em&gt;. To be considered an unplanned readmission patients must initially be discharged from the inpatient setting. A patient that is discharged from the emergency department or observation setting cannot be readmitted (0% probability) because they did not meet the inpatient requirement pertaining to the inpatient index admission. Similarly, even after a patient is admitted to the inpatient setting, we still do not yet know their what their discharge disposition or discharge diagnosis will be. If the patient leaves against medical advice or is assigned a cancer-related discharge, for instance, they meet a different set of exclusion criteria and cannot be readmitted (again, 0% probability). While the specific criteria behind the definition of a readmission makes practical sense, it creates a couple of challenges to training, testing, and deploying a readmission risk model that is to be leveraged while patients are still in the hospital.&lt;/p&gt;

&lt;p&gt;At the end of the day, we need to develop the model using the same data that we want it to perform well on in production. For the &lt;em&gt;in-hospital&lt;/em&gt; use case, &lt;em&gt;observational&lt;/em&gt; and &lt;em&gt;emergency department&lt;/em&gt; patients that would ultimately be excluded at discharge must also be excluded from model development. These patients may skew the model toward predicting 0% readmission probability since they are guaranteed to be 0% risk as defined by CMS. This puts us in a tight spot. When &lt;a href=&quot;http://healthcare.ai/blog/2016/12/15/model-evaluation-using-roc-curves/&quot;&gt;evaluating the model&lt;/a&gt;, it may appear to have higher accuracy by skewing toward low probabilities because it was improperly trained on data that should have been excluded. For the post-discharge use case, the discharge type is available and the model can match the CMS definition more closely. This will likely lead to increased accuracy overall, as more use-case specific data is available.&lt;/p&gt;

&lt;p&gt;From our experience, understanding the definition of the readmission outcome variable, the specific use case, and the timing/target is crucial. There is clearly a trade-off between timeliness and accuracy, and to have the greatest impact on patient outcomes, it is important to develop readmission risk models based on data that reflects the use case in production. Again, the best ML model should answer a specific question, using specific data, with an actionable result. Keep these things in mind and your models will improve.&lt;/p&gt;

&lt;p&gt;Thanks for reading and please &lt;a href=&quot;http://healthcare.ai/contact&quot;&gt;reach out&lt;/a&gt; with any questions or comments!&lt;/p&gt;</content><author><name>Taylor Larsen</name></author><category term="overview" /><summary type="html">This post describes the importance of understanding the business questions, use cases, and data when creating a readmission risk model</summary></entry><entry><title type="html">Which regions of the US are healthy?</title><link href="http://healthcare.ai/blog/2017/01/08/us-health-by-county/" rel="alternate" type="text/html" title="Which regions of the US are healthy?" /><published>2017-01-08T16:00:00-07:00</published><updated>2017-01-08T16:00:00-07:00</updated><id>http://healthcare.ai/blog/2017/01/08/us-health-by-county</id><content type="html" xml:base="http://healthcare.ai/blog/2017/01/08/us-health-by-county/">&lt;p&gt;While our previous posts have focused on healthcare machine learning, we’re also excited to post analyses of health data using R and Python. We do this to hopefully elevate the national discussion around health data, enhance the community’s understanding of health in the United States (US), and provide guidance as to how communities and health systems might increase the quality and length of people’s lives. Health Catalyst is an outcomes improvement company, and we realize that the inpatient setting is only one of several venues that affect a person’s health trajectory. Understanding the big picture of health is another way to approach outcomes improvements. These posts will not only attempt to educate on findings about health, but also on how to use R/Python for health data analysis, so we’ll always post links to the &lt;a href=&quot;https://gist.github.com/levithatcher/070496ca48c165d7ced37e0ffcd24dc7&quot;&gt;relevant code&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Those who have been in healthcare for any significant amount of time have heard that social determinants of health (SDOH) are important to healthcare outcomes. While it’s hard to overstate the importance of these factors, they’re often not well understood and overshadowed by inpatient optimizations when discussing outcomes improvement. This post is the first in a series where we’ll attempt to untangle the drivers behind population health differences across the US. Today we’ll talk about where the US stands from region to region in terms of social determinants of health. In subsequent posts we’ll discuss whether these differences mostly related to income, air pollution, access to healthy food, long commutes, access to healthcare, opioid addiction, or alcohol abuse.&lt;/p&gt;

&lt;p&gt;To try and answer that we’ll &lt;a href=&quot;https://gist.github.com/levithatcher/070496ca48c165d7ced37e0ffcd24dc7&quot;&gt;use R&lt;/a&gt; and &lt;a href=&quot;http://www.countyhealthrankings.org/sites/default/files/2015%20CHR%20Analytic%20Data.csv&quot;&gt;data&lt;/a&gt; from &lt;a href=&quot;http://www.countyhealthrankings.org/&quot;&gt;countyhealthrankings.org&lt;/a&gt;, which is a fantastic resource on SDOH comparisons by county. We’ll start by presenting a choropleth map of median household 2015 &lt;a href=&quot;http://www.countyhealthrankings.org/measure/median-household-income&quot;&gt;income by county&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Post10CountyHealthOverview/MedianIncomeByCounty.jpg&quot; alt=&quot;IncomeByCounty&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Of course, what we find is that there are large regional differences in household income. Broadly, the Northeast, the West Coast, and metropolitan areas are associated with higher personal incomes, compared with rural areas and the South. Note that occasionally there is high intra-state variation, such as in Texas, compared to the more uniform median incomes across counties in Minnesota. But how do these regional variations in incomes correspond with healthcare outcomes? Data on &lt;a href=&quot;http://www.countyhealthrankings.org/measure/low-birthweight&quot;&gt;Low Birth-Weight&lt;/a&gt; (LBW), i.e., live births under ~5 lbs 8 oz (2500 g), provides a &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pubmed/7633862&quot;&gt;helpful link&lt;/a&gt; between social determinants and actual healthcare outcomes, as&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“&lt;a href=&quot;http://www.countyhealthrankings.org/measure/low-birthweight&quot;&gt;LBW indicates maternal exposure to health risks&lt;/a&gt; in all categories of health factors, including her health behaviors, access to health care the social and economic environment she inhabits, and environmental risks to which she is exposed. In terms of the infant’s health outcomes, LBW serves as a predictor of premature mortality and/or morbidity over the life course and for potential cognitive development problems.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Pulling data from &lt;a href=&quot;http://www.countyhealthrankings.org/measure/low-birthweight&quot;&gt;here&lt;/a&gt;, and &lt;a href=&quot;https://gist.github.com/levithatcher/070496ca48c165d7ced37e0ffcd24dc7&quot;&gt;processing with R&lt;/a&gt;, we plot the percentage of county live births with birth-weight under 5 lbs 8 oz:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Post10CountyHealthOverview/LowBirthWeightByCounty.jpg&quot; alt=&quot;LBWByCounty&quot; /&gt;&lt;/p&gt;

&lt;p&gt;While there’s a lot that could be unpacked here, we’ll simply note that the same regions that had lower personal incomes also have a higher percentage of LBW. Not a huge surprise—it is surprising, however, how much intra-state variation is present (like in NV and CO) and how the Deep South has rates of LBW that are often twice that of Minnesota and Wisconsin.&lt;/p&gt;

&lt;p&gt;While income appears to be associated with new-born morbidity and mortality, how does it affect populations later in life? We use &lt;a href=&quot;http://www.countyhealthrankings.org/measure/premature-death-ypll&quot;&gt;premature mortality&lt;/a&gt; &lt;a href=&quot;http://www.countyhealthrankings.org/sites/default/files/2015%20CHR%20Analytic%20Data.csv&quot;&gt;data&lt;/a&gt; from &lt;a href=&quot;http://www.countyhealthrankings.org/&quot;&gt;countyhealthrankings.org&lt;/a&gt;, where a premature death is defined as occurring before 70 years of age, to answer this question. For each county, per 100k people, the years of death before 75 are summed. Think of it as incidence of early death, per county:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Post10CountyHealthOverview/PrematureDeathByCounty.jpg&quot; alt=&quot;PrematureDeathByCounty&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Compared to LBW, it appears that premature mortality more closely corresponds with median county income. Note how the high incidence of premature mortality across Arkansas, Tennessee, and Kentucky closely tracks income (comparing with the first figure). Broadly, Appalachia appears to suffer more from deaths of prime-age adults compared to LBW (while the South appears to suffer greatly from both). Note that while the rust belt (i.e., PA, OH, IN, MI, IL, and WI) certainly has other issues, they seem to be doing a good job of keeping prime-age people alive, especially compared to Appalachia and the Deep South.&lt;/p&gt;

&lt;p&gt;While it’s old-hat to say that population health in the Deep South isn’t fantastic, let’s go one step further and see which counties in the US punch above their weight when it comes to using resources effectively. In other words, which counties are doing well for how poor they are. This is the metric that will let us understand what it is that poor and middle-income counties do well in terms of keeping people healthy.&lt;/p&gt;

&lt;p&gt;To get at this, we create percentiles for each county in terms of LBW (where 100 is best) and then subtract (for each county) the percentiles for income. We can call this the county Punch-Above-Their-Weight Index or PATWI for short. Before plotting the entire country, let’s look at LBW PATWI for the top ten counties in terms of income:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Post10CountyHealthOverview/TableHighestIncomeAndLBW.png&quot; alt=&quot;TableHighestIncomeandLBW&quot; /&gt;&lt;/p&gt;

&lt;p&gt;First, in this and the following tables, the PATWI column is just the fifth column minus the fourth column. While the counties above do have good scores in terms of LBW, it’s difficult for rich counties to punch above their weight, since they’re the 800-lb gorillas. We do, however, see the benefit of the PATWI, since the richest counties in the US &lt;em&gt;aren’t&lt;/em&gt; those with the best LBW scores.&lt;/p&gt;

&lt;p&gt;Which counties have the best LBW, considering their income?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Post10CountyHealthOverview/TableHighestLBWPATWIAndIncome.png&quot; alt=&quot;TableHighestPATWIAndIncome&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It’s impressive that these counties, which have median incomes one-third of that of Loudoun County (VA), have better LBW scores than Loudoun County. Note that the best LBW PATWI scores come from a scattered grouping of states, although, Michigan (MI) impressively has three entries and Missouri (MO) has two. That’s definitely good news for MI and MO public health officials. Note that this PATWI measure doesn’t just bias towards the poorest counties, either. While Buffalo County, SD—perhaps the poorest county in the nation—has a high LDW PATWI score, none of the counties from the Deep South or Appalachia show up in this list. Here’s LDW PATWI score for all counties:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Post10CountyHealthOverview/LBWComparedToIncomeByCounty.jpg&quot; alt=&quot;LBWComparedToIncome&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note that positive values here denote that the county is doing better at LBW than expected, based on their income*. Amongst other findings, we see that even though northern half of West Virginia is quite poor, they’re doing better than expected at helping mothers carry and deliver healthy babies. The Deep South, however, is doing about as poorly (or worse) than one would expect by looking at their income along. Note that Missouri is doing better than expected, as is rural Oregon, Minneapolis, and Wisconsin. Recall that metro areas tend to be richer than rural areas, so it’s impossible for richest areas like the Bay Area and NYC tend to have a high score (since their percentiles can’t go over 100)—this limitation makes this plot more of a measure of how middle and low income counties are doing relative to their income.
Let’s do the same for the premature mortality metric we discussed above—in other words, which counties are doing a great job of avoiding early mortality. We’ll start with the richest counties:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Post10CountyHealthOverview/TableHighestIncomeAndPrematureDeath.png&quot; alt=&quot;TableHighestIncomeAndLBW&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Yup, the richest counties are great at keeping people alive—even more so than avoiding low birth-weight (compare with the first table above). But, which poor or middle income counties are best at punching above their weight when it comes to keeping their citizens alive?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Post10CountyHealthOverview/TableHighestPrematureDeathPATWIAndIncome.png&quot; alt=&quot;TableHighestLBWPATWIAndIncome&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It’s impressive how these relatively poor counties are achieving the top 10-20th percentile in terms of avoiding premature deaths (note that we’re using higher percentiles to mean good outcomes). It is an interesting mix of counties, indeed. Santa Cruz (AZ), Presidio County (TX), and Maverick County (TX) border Mexico; Crowley County (CO) has the largest per-capita prison population in the country. Madison County, home to BYU-Idaho, is &lt;a href=&quot;http://www.slate.com/articles/life/map_of_the_week/2012/02/mormon_population_in_the_u_s_an_interactive_map.html&quot;&gt;~80% Mormon&lt;/a&gt;, which likely means that county overall has low rates of alcohol, tobacco, and drug dependency. In a future post we’ll go into how certain counties are punching above their weight, and for now offer the national view of premature-death PATWI score:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Post10CountyHealthOverview/PrematureDeathComparedToIncomeByCounty.jpg&quot; alt=&quot;PrematureDeathComparedToIncome&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Recall that darker means that the county is doing well. At this level, what we notice is that Wisconsin, Michigan, and Missouri are doing a good job keeping prime-age people alive compared to Nevada and Wyoming. Knowing why this is occurring can significantly change how a health system interacts with its patients.&lt;/p&gt;

&lt;p&gt;At Health Catalyst, we strive to understand the significant way social determinants of health can affect decision making at health systems from the Deep South to the Bay Area. Our clients are located all across the continent. High-value improvements in one health system are not necessarily the best everywhere, and we’d be cheating ourselves to only look for improvements at inpatient units. We’re committed to leveraging the tools of population health to improve patient outcomes across the board. 
This post is the first of many on population health, and in a future post we’ll dig more into which social determinants are most driving regional variations of LBW and premature death.&lt;/p&gt;

&lt;p&gt;Thanks for reading and please &lt;a href=&quot;http://healthcare.ai/contact&quot;&gt;reach out&lt;/a&gt; with any questions or comments!&lt;/p&gt;

&lt;p&gt;* The distribution of county median income has a long tail, which means that when subtracting county income percentiles from the corresponding LBW or premature death percentiles, the result is typically positive.&lt;/p&gt;</content><author><name>Levi Thatcher</name></author><category term="overview" /><summary type="html">While our previous posts have focused on healthcare machine learning, we’re also excited to post analyses of health data using R and Python. We do this to hopefully elevate the national discussion around health data, enhance the community’s understanding of health in the United States (US), and provide guidance as to how communities and health systems might increase the quality and length of people’s lives. Health Catalyst is an outcomes improvement company, and we realize that the inpatient setting is only one of several venues that affect a person’s health trajectory. Understanding the big picture of health is another way to approach outcomes improvements. These posts will not only attempt to educate on findings about health, but also on how to use R/Python for health data analysis, so we’ll always post links to the relevant code.</summary></entry><entry><title type="html">Data leakage in healthcare machine learning</title><link href="http://healthcare.ai/blog/2017/01/06/data-leakage-in-healthcare-machine-learning/" rel="alternate" type="text/html" title="Data leakage in healthcare machine learning" /><published>2017-01-06T15:00:00-07:00</published><updated>2017-01-06T15:00:00-07:00</updated><id>http://healthcare.ai/blog/2017/01/06/data-leakage-in-healthcare-machine-learning</id><content type="html" xml:base="http://healthcare.ai/blog/2017/01/06/data-leakage-in-healthcare-machine-learning/">&lt;p&gt;Note: this is a technical post.&lt;/p&gt;

&lt;p&gt;To leverage lessons learned during our model building engagements here at Health Catalyst, let’s explore the &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.365.7769&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;subject of data leakage&lt;/a&gt;. Data leakage occurs when a predictive model is trained using information that is available in training data but not actually available for predicting outcomes in production. Models with data leakage tend to be very accurate in development, but perform poorly in production, where they are ultimately used.&lt;/p&gt;

&lt;p&gt;More specifically, leakage in the context of healthcare machine learning occurs when:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A feature is used to train the model that would &lt;em&gt;not be available in production at the time of prediction&lt;/em&gt;. An example of this might be using the number of oral medications a patient is currently taking to predict length of stay at admission when medication reconciliation may not take place for up to 24 hours following admission.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A feature is used to train the model that would &lt;em&gt;not be available in production prior to the outcome variable being populated&lt;/em&gt;. An example of this might be using a response from a quality of life phone survey to predict readmissions when the survey is not administered until three months after the discharge. At that point, it would already be known whether the patient had been readmitted or not. When training a model, the algorithm has no idea whether a feature was populated prior to the target variable in the same row.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A feature is used to train the model that is &lt;em&gt;outside the scope of the model’s intended use case&lt;/em&gt;. An example of this might exist when trying to predict the probability of a patient having heart failure and using the hospital unit associated with the patient without considering that the hospital unit may be disease or service specific (like a cardiac unit).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;em&gt;correct outcome is leaked into the test data&lt;/em&gt; through a variable that inherently proxies for the outcome. An example of this might be predicting the probability that a patient will pay their balance due on time and using a variable that indicates whether the patient has been contacted by the hospital accounts receivable department which only takes place when a patient is late on payment.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;What can happen?&lt;/em&gt; Leakage can lead to poor generalization, overfitting, and over-estimation of a model’s performance. The ultimate negative impact of leakage is the deployment of a less useful model than if no leakage was present. Considering the examples described above, leakage can result in the inclusion of a variable that appears predictive during training, but due to missing data and/or imputation in production, the variable is either not predictive, is skewed in power, or only appropriate in certain use cases. Leakage will often raise the accuracy of a model in training, but make predictions that can’t be trusted in deployment.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;How does one prevent it?&lt;/em&gt; Through proactive analysis of potentially predictive variables and direct involvement of subject matter experts (SMEs) during variable selection, leakage can most likely be avoided. It is important to profile each variable to determine when it was generated and how its values are distributed when comparing training data to production data. Involving clinical, operational, and data SMEs will reduce the likelihood of leakage by improving understanding of nuances in the data. It is also important to understand when the prediction needs to take place so that predictive variables can be sourced accordingly; and the timing of the prediction should be based on the use case for the predictive model output. In summary, one must scrutinize the data they are using and keep the business question in mind when building the model.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Does an existing model have data leakage?&lt;/em&gt; As described above, profiling each variable and consulting with SMEs may help to identify more obvious leakage. Another way of identifying leakage is to compare the model’s actual performance in production to the model’s performance observed during training and testing. This can expose important discrepancies that might be the result of leakage and in depth analysis comparing training data to production data may be required.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;How does one fix an existing model?&lt;/em&gt; If leakage is identified after a model has been developed and/or deployed, it is important to remediate the issue. Redefining a variable and retraining the model can eliminate leakage and allow the variable to remain in the model. Another solution for eliminating leakage is to remove the variable and retrain the model, while exploring other leakage free variables and proxies that could be added. Though perceived model performance might take a hit when data leakage is avoided/eliminated, the predictions on new data in production will be more accurate and useful.&lt;/p&gt;

&lt;p&gt;Clearly, leakage is an issue that we face on a regular basis, especially when dealing with all the complexities associated with healthcare data. Through experience and diligent analysis, it is an issue we can easily avoid. &lt;a href=&quot;http://healthcare.ai/&quot;&gt;Healthcare.ai&lt;/a&gt; has several tools to help understand the timing, scope, and source of variables when model building, which can be used to eliminate data leakage during the model’s initial creation. Taking these steps will mean deploying useful models that are widely adopted, and ultimately improve healthcare outcomes.&lt;/p&gt;

&lt;p&gt;Thanks for reading and please &lt;a href=&quot;http://healthcare.ai/contact&quot;&gt;reach out&lt;/a&gt; with any questions or comments!&lt;/p&gt;</content><author><name>Taylor Larsen</name></author><category term="overview" /><summary type="html">This blog will describe data leakage along with its causes, impacts, and fixes in the context of healthcare machine learning</summary></entry><entry><title type="html">Applications of healthcare machine learning</title><link href="http://healthcare.ai/blog/2016/12/22/applications-of-healthcare-machine-learning/" rel="alternate" type="text/html" title="Applications of healthcare machine learning" /><published>2016-12-22T21:39:11-07:00</published><updated>2016-12-22T21:39:11-07:00</updated><id>http://healthcare.ai/blog/2016/12/22/applications-of-healthcare-machine-learning</id><content type="html" xml:base="http://healthcare.ai/blog/2016/12/22/applications-of-healthcare-machine-learning/">&lt;p&gt;Now that we have been through some of the applications of machine learning (ML) in mainstream technology, we thought it would be nice to give a broader overview of some of the different types of ML and how they might be applied to improve patient care. &lt;a href=&quot;http://healthcare.ai/blog/2016/12/21/which-algorithms-are-in-healthcareai/&quot;&gt;We explored the algorithms&lt;/a&gt; that currently make up healthcare.ai, and alluded to the fact that there is lots of room for expansion. We’ll take this post as an opportunity to speculate on where healthcare ML could go in the near and distant future. Along the way, we’ll discuss the different types of ML algorithms and give examples of their use in healthcare. 
At its most basic definition, machine learning refers to a group of algorithms that learn from data. These algorithms are different from &lt;a href=&quot;https://fiftyexamples.readthedocs.io/en/latest/celsius.html&quot;&gt;conventional ones&lt;/a&gt; since they work using examples rather than rules. If you went to the hospital for flu like symptoms, a doctor thinking along the lines of traditional algorithms might say, “You have a fever, aches, general weakness, and no cold symptoms. This looks like the flu.” A different doctor, thinking like an ML algorithm, would say, “Hmmm, your symptoms are the same as 50 recent patients who had the flu. You probably do too.” Silly example, but it’s worth noting a couple of things. First, the ML doctor doesn’t actually need to know anything about the flu before they start making diagnoses. Second, their diagnoses probably won’t be very good until they have seen a lot of examples to compare against.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Classification vs. Regression&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The above scenario is an example of a classification machine learning problem. A classification algorithm will give a probability score of a person having the disease, or, more broadly, the probability of event happening vs. not. Healthcare.ai has already implemented some of the simplest &lt;a href=&quot;http://healthcare.ai/blog/2016/12/21/which-algorithms-are-in-healthcareai/&quot;&gt;algorithms&lt;/a&gt; to answer questions like:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;What is the likelihood that a patient will develop a central line infection?&lt;/li&gt;
  &lt;li&gt;What is the likelihood that a COPD patient will be readmitted within 90 days of discharge?&lt;/li&gt;
  &lt;li&gt;What is the likelihood that a person will no-show for their appointment?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These questions are posed with a lot of example data and the expectation that a model will give a probability from 0 (low) to 1 (high). It’s up to us to draw the line of what we call a positive prediction and what we call a negative prediction. On the other hand, a regression algorithm will predict a continuous value. Here are some examples of questions that we have or plan to tackle using regression algorithms:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;How many days will a patient need to stay in the hospital?&lt;/li&gt;
  &lt;li&gt;How many people do we need on staff in the ED on a given night?&lt;/li&gt;
  &lt;li&gt;How much money will a patient cost the health system over the next year?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There are a lot of exciting questions that can be answered with very basic machine learning! As we’ve said before, we are focused on trying to answer the questions that will make the most impact right now. Luckily for us, there is still a lot of low-hanging fruit in healthcare for our team to address. As long as there is good example data, ML could help answer a huge range of questions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Supervised vs. Unsupervised&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;All the problems that this post has discussed so far are supervised machine learning problems. For each of these there is a ground truth associated with every patient example being used to train the model. The other major type of machine learning is unsupervised. There is no ground truth associated with the data. The algorithms in this category are largely related to identifying patterns and similarity, and using them to group or stratify data into different categories. This type of functionality is a high priority capability that we are working on implementing in healthcare.ai. In the very near future, we hope to be able to use clustering methods and anomaly detection to answer questions like:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Does this patient (who hasn’t been associated with diabetes) belong in a diabetes registry? Or a heart disease registry? And with what likelihood?&lt;/li&gt;
  &lt;li&gt;How similar are my high-utilizing patients? Do they fall into particular clusters? What can we learn about the characteristics of these separate clusters?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These questions are typically more nebulous than supervised learning problems, but useful insights can still be gathered. For example, there would be value in labeling a non-diabetic patient as a person to watch and intervene before they ever develop diabetes. This is great information to have and ML will absolutely make an impact by answering such questions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Future&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The third arm of machine learning that has especially gotten a lot of attention lately is in Artificial Intelligence (AI), mostly implemented with what’s called deep learning. &lt;a href=&quot;https://www.tesla.com/autopilot&quot;&gt;Self-driving cars&lt;/a&gt;, &lt;a href=&quot;https://www.facebook.com/notes/mark-zuckerberg/building-jarvis/10154361492931634/&quot;&gt;home assistants&lt;/a&gt;, and &lt;a href=&quot;http://www.nytimes.com/2016/12/14/magazine/the-great-ai-awakening.html?smid=pl-share&amp;amp;_r=0&quot;&gt;translation services&lt;/a&gt; are some applications of AI. This is the cutting edge in ML right now. In the 2-5 year timeframe, we will start to see more mainstream impact from these techniques. In healthcare, the first big use case is for image analysis in radiology and pathology departments. It’s possible that computers will learn to assess images with high speed and accuracy in the very near future. When the community is ready for adoption, we will be excited to provide these tools in healthcare.ai.
Hopefully this post helped you to understand the different types of machine learning and begin to think about the types of questions that can be reliably answered. There will never be any shortage of work for machine learning. The bottleneck is the number of people with the necessary expertise. As we’ve said before, another goal of healthcare.ai is to help commoditize machine learning in healthcare. If you’d like to get involved, please &lt;a href=&quot;https://github.com/HealthCatalystSLC/healthcareai-r&quot;&gt;start using and contributing to the package&lt;/a&gt; on your data and feel free to &lt;a href=&quot;http://healthcare.ai/contact&quot;&gt;reach out&lt;/a&gt; with questions!&lt;/p&gt;</content><author><name>Mike Mastanduno</name></author><category term="overview" /><summary type="html">Now that we have been through some of the applications of machine learning (ML) in mainstream technology, we thought it would be nice to give a broader overview of some of the different types of ML and how they might be applied to improve patient care. We explored the algorithms that currently make up healthcare.ai, and alluded to the fact that there is lots of room for expansion. We’ll take this post as an opportunity to speculate on where healthcare ML could go in the near and distant future. Along the way, we’ll discuss the different types of ML algorithms and give examples of their use in healthcare. 
At its most basic definition, machine learning refers to a group of algorithms that learn from data. These algorithms are different from conventional ones since they work using examples rather than rules. If you went to the hospital for flu like symptoms, a doctor thinking along the lines of traditional algorithms might say, “You have a fever, aches, general weakness, and no cold symptoms. This looks like the flu.” A different doctor, thinking like an ML algorithm, would say, “Hmmm, your symptoms are the same as 50 recent patients who had the flu. You probably do too.” Silly example, but it’s worth noting a couple of things. First, the ML doctor doesn’t actually need to know anything about the flu before they start making diagnoses. Second, their diagnoses probably won’t be very good until they have seen a lot of examples to compare against.</summary></entry><entry><title type="html">Which algorithms are in healthcare.ai?</title><link href="http://healthcare.ai/blog/2016/12/21/which-algorithms-are-in-healthcareai/" rel="alternate" type="text/html" title="Which algorithms are in healthcare.ai?" /><published>2016-12-21T20:17:11-07:00</published><updated>2016-12-21T20:17:11-07:00</updated><id>http://healthcare.ai/blog/2016/12/21/which-algorithms-are-in-healthcareai</id><content type="html" xml:base="http://healthcare.ai/blog/2016/12/21/which-algorithms-are-in-healthcareai/">&lt;p&gt;Machine learning has been around for decades and has been used to solve lots of problems. Some of these include &lt;a href=&quot;http://ats.cs.ut.ee/u/kt/hw/spam/spam.pdf&quot;&gt;spam filtering&lt;/a&gt; for email, &lt;a href=&quot;http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html&quot;&gt;suggestions on Netflix&lt;/a&gt;, &lt;a href=&quot;http://qz.com/571007/the-magic-that-makes-spotifys-discover-weekly-playlists-so-damn-good/&quot;&gt;optimized playlists on Spotify&lt;/a&gt;, &lt;a href=&quot;https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf&quot;&gt;custom recommendations on Amazon&lt;/a&gt;, &lt;a href=&quot;https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78#.7b9c9jmg7&quot;&gt;facial recognition on Facebook&lt;/a&gt;, &lt;a href=&quot;https://research.googleblog.com/2015/09/google-voice-search-faster-and-more.html&quot;&gt;voice recognition&lt;/a&gt; on your phone, &lt;a href=&quot;http://www.nytimes.com/2016/12/14/magazine/the-great-ai-awakening.html&quot;&gt;language translation&lt;/a&gt; on demand, &lt;a href=&quot;http://fusion.net/story/142326/the-new-google-photos-app-is-disturbingly-good-at-data-mining-your-photos/&quot;&gt;image search&lt;/a&gt; in your photo app, and &lt;a href=&quot;https://www.kaggle.com/wiki/DataScienceUseCases&quot;&gt;many more&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;While reading that long and varied list, you may be wondering where healthcare stands by comparison. Even though machine learning can solve many problems in healthcare, the field has not yet seen significant adoption. As &lt;a href=&quot;http://healthcare.ai/blog/2016/12/01/welcome-to-healthcareai/&quot;&gt;we’ve mentioned&lt;/a&gt;, the goal of healthcare.ai is to change that.&lt;/p&gt;

&lt;p&gt;We plan to bring the benefits of machine learning into healthcare by starting with the low-hanging fruit. Health Catalyst is a very practical company and that is reflected in &lt;a href=&quot;http://healthcare.ai/&quot;&gt;healthcare.ai&lt;/a&gt;. While many of the machine learning projects mentioned above are using advanced algorithms like &lt;a href=&quot;https://en.wikipedia.org/wiki/Deep_learning&quot;&gt;deep learning&lt;/a&gt;, healthcare.ai is instead starting with the workhorses of the algorithm world. Note that this a different approach to healthcare machine learning compared to that of &lt;a href=&quot;https://research.google.com/teams/brain/healthcare/&quot;&gt;Google&lt;/a&gt; and &lt;a href=&quot;http://searchhealthit.techtarget.com/opinion/Microsoft-Project-Adam-may-reach-healthcare-specialties&quot;&gt;Microsoft&lt;/a&gt;, which are focusing on the sexier (but less practical) deep learning applications in healthcare.&lt;/p&gt;

&lt;p&gt;Before starting the discussion on healthcare.ai algorithm choices, I should note that we’ll focus on our R package and on &lt;a href=&quot;https://en.wikipedia.org/wiki/Statistical_classification&quot;&gt;classification&lt;/a&gt; (rather than regression), since &lt;em&gt;most&lt;/em&gt; problems in healthcare revolve around predicting &lt;a href=&quot;http://healthcare.ai/blog/2016/12/12/what-models-has-health-catalyst-created/&quot;&gt;Yes or No&lt;/a&gt; rather than a continuous variable. To make the terminology clear, it should also be stated that a machine learning algorithm, when paired with data, leads to a model. The algorithms exist off the shelf. The great value-add comes from pairing the proper algorithm with the data of interest. Healthcare.ai has open-sourced tools that allow you to easily match your data with suitable algorithms, create models, and help you answer your most important business questions. The models that you and Health Catalyst create are proprietary, but the tools used to make those models are free.&lt;/p&gt;

&lt;p&gt;Arguably the most simple and common algorithm when trying to classify things via machine learning is &lt;a href=&quot;https://en.wikipedia.org/wiki/Logistic_regression&quot;&gt;logistic regression&lt;/a&gt;. (Note that despite the name, this algorithm is used for classification problems.) We love it because it’s easy to use, quick to finish, and easy to interpret. We’ve been using this algorithm, but with a twist to it.&lt;/p&gt;

&lt;p&gt;We built healthcare.ai with the goal of providing users with guidance as to which &lt;a href=&quot;https://en.wikipedia.org/wiki/Feature_(machine_learning)&quot;&gt;features&lt;/a&gt; (i.e., variables) were predictive and worth using when building a model. This drove us to use &lt;a href=&quot;https://en.wikipedia.org/wiki/Lasso_(statistics)&quot;&gt;lasso&lt;/a&gt;, which is a linear model much like logistic regression, but it provides feedback on which features should or shouldn’t be included in the model. You might say, “Well, couldn’t logistic regression just ignore features that weren’t predictive?” Yes, but when the user has brought 20-40 variables into a focused dataset—what Health Catalyst calls a source area mart—to see if they help predict Sepsis, they’ll often only want to keep those variables that are predictive, as ETL processes often have hard resource constraints. With knowledge of how important each feature is, one can often remove many non-predictive variables from a model without any significant loss in accuracy.&lt;/p&gt;

&lt;p&gt;Next to linear models like lasso and logistic regression, the most common algorithm in machine learning is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Random_forest&quot;&gt;random forest&lt;/a&gt;. It’s different in that it can model non-linear relationships accurately. The random forest algorithm is an ensemble method, which aggregates the result of 100+ randomized decision trees to produce a prediction. While it’s a little harder to interpret than linear algorithms (like lasso), it typically doesn’t need much &lt;a href=&quot;https://en.wikipedia.org/wiki/Hyperparameter_optimization&quot;&gt;hyperparameter tuning&lt;/a&gt;, can run quite quickly, and from our experience often provides more accurate models (compared to linear algorithms) for common healthcare questions. These reasons drove us to include a random forest option in healthcare.ai.&lt;/p&gt;

&lt;p&gt;To back up a bit, in typical machine learning problems row order doesn’t matter. If you think of the simple example of housing data in Salt Lake City to determine the relationship between square footage and house price, it doesn’t matter if the row for house 10045 was listed before house 10057 in the dataset. Those two rows are treated independently. In longitudinal datasets however, the relationship between the rows often &lt;em&gt;does&lt;/em&gt; matter. In certain clinical datasets, we often find multiple entries for the same person, showing the person’s progression over time. When this progression is important to the business question that’s being addressed with machine learning, basic machine learning might not be suitable.&lt;/p&gt;

&lt;p&gt;This frequent longitudinal aspect of healthcare data is why we’re excited to offer linear &lt;a href=&quot;https://en.wikipedia.org/wiki/Mixed_model&quot;&gt;mixed models&lt;/a&gt; in our the R version of healthcare.ai. Mixed models offer the ability to combine a personal trend with a population trend. It’s called a mixed model because it combines fixed effects (i.e., those that relate to the population as a whole) with random effects (i.e., those that are innate to that individual). &lt;a href=&quot;http://www.bodowinter.com/tutorial/bw_LME_tutorial.pdf&quot;&gt;This paper&lt;/a&gt; provides a good introduction to the topic. From our experience, this algorithm is slow compared to random forest and lasso, but can create a better model if the prediction at hand significantly depends on a person’s history (i.e., think diabetic amputation risk rather than &lt;a href=&quot;https://en.wikipedia.org/wiki/Central_venous_catheter#Bloodstream_infections&quot;&gt;CLABSI&lt;/a&gt;). As always, healthcare.ai makes it easy to see how this algorithm performs on your dataset, and determine if it does a better job than the more common lasso and random forest algorithms.&lt;/p&gt;

&lt;p&gt;Again, the goal of healthcare.ai is to help the medical community use machine learning to improve healthcare outcomes. On the first pass, we have implemented what we feel are the simplest and most effective algorithms specific to healthcare data. We’ll certainly expand in the future, but for now there are a lot of efficiency gains to be &lt;achieved&gt;&lt;/achieved&gt; with basic algorithms, standardized performance metrics, smart implementation, and centralized documentation.&lt;/p&gt;

&lt;p&gt;If you want more detail, check out &lt;a href=&quot;https://github.com/HealthCatalystSLC/healthcareai-r&quot;&gt;our code&lt;/a&gt;. If you have questions or feedback, &lt;a href=&quot;http://healthcare.ai/contact&quot;&gt;contact us&lt;/a&gt;!&lt;/p&gt;</content><author><name>Levi Thatcher</name></author><category term="algorithms" /><summary type="html">Machine learning has been around for decades and has been used to solve lots of problems. Some of these include spam filtering for email, suggestions on Netflix, optimized playlists on Spotify, custom recommendations on Amazon, facial recognition on Facebook, voice recognition on your phone, language translation on demand, image search in your photo app, and many more.</summary></entry></feed>
